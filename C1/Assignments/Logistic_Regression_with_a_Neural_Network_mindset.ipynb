{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with a Neural Network mindset\n",
    "\n",
    "Welcome to your first (required) programming assignment! You will build a logistic regression classifier to recognize  cats. This assignment will step you through how to do this with a Neural Network mindset, and will also hone your intuitions about deep learning.\n",
    "\n",
    "**Instructions:**\n",
    "- Do not use loops (for/while) in your code, unless the instructions explicitly ask you to do so.\n",
    "- Use `np.dot(X,Y)` to calculate dot products.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a learning algorithm, including:\n",
    "    - Initializing parameters\n",
    "    - Calculating the cost function and its gradient\n",
    "    - Using an optimization algorithm (gradient descent) \n",
    "- Gather all three functions above into a main model function, in the right order.\n",
    "\n",
    "## Important Note on Submission to the AutoGrader\n",
    "\n",
    "Before submitting your assignment to the AutoGrader, please make sure you are not doing the following:\n",
    "\n",
    "1. You have not added any _extra_ `print` statement(s) in the assignment.\n",
    "2. You have not added any _extra_ code cell(s) in the assignment.\n",
    "3. You have not changed any of the function parameters.\n",
    "4. You are not using any global variables inside your graded exercises. Unless specifically instructed to do so, please refrain from it and use the local variables instead.\n",
    "5. You are not changing the assignment code where it is not required, like creating _extra_ variables.\n",
    "\n",
    "If you do any of the following, you will get something like, `Grader Error: Grader feedback not found` (or similarly unexpected) error upon submitting your assignment. Before asking for help/debugging the errors in your assignment, check for these first. If this is the case, and you don't remember the changes you have made, you can get a fresh copy of the assignment by following these [instructions](https://www.coursera.org/learn/neural-networks-deep-learning/supplement/iLwon/h-ow-to-refresh-your-workspace)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [1 - Packages](#1)\n",
    "- [2 - Overview of the Problem set](#2)\n",
    "    - [Exercise 1](#ex-1)\n",
    "    - [Exercise 2](#ex-2)\n",
    "- [3 - General Architecture of the learning algorithm](#3)\n",
    "- [4 - Building the parts of our algorithm](#4)\n",
    "    - [4.1 - Helper functions](#4-1)\n",
    "        - [Exercise 3 - sigmoid](#ex-3)\n",
    "    - [4.2 - Initializing parameters](#4-2)\n",
    "        - [Exercise 4 - initialize_with_zeros](#ex-4)\n",
    "    - [4.3 - Forward and Backward propagation](#4-3)\n",
    "        - [Exercise 5 - propagate](#ex-5)\n",
    "    - [4.4 - Optimization](#4-4)\n",
    "        - [Exercise 6 - optimize](#ex-6)\n",
    "        - [Exercise 7 - predict](#ex-7)\n",
    "- [5 - Merge all functions into a model](#5)\n",
    "    - [Exercise 8 - model](#ex-8)\n",
    "- [6 - Further analysis (optional/ungraded exercise)](#6)\n",
    "- [7 - Test with your own image (optional/ungraded exercise)](#7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1 - Packages ##\n",
    "\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment. \n",
    "- [numpy](https://numpy.org/doc/1.20/) is the fundamental package for scientific computing with Python.\n",
    "- [h5py](http://www.h5py.org) is a common package to interact with a dataset that is stored on an H5 file.\n",
    "- [matplotlib](http://matplotlib.org) is a famous library to plot graphs in Python.\n",
    "- [PIL](https://pillow.readthedocs.io/en/stable/) and [scipy](https://www.scipy.org/) are used here to test your model with your own picture at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "### v1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from lr_utils import load_dataset\n",
    "from public_tests import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2 - Overview of the Problem set ##\n",
    "\n",
    "**Problem Statement**: You are given a dataset (\"data.h5\") containing:\n",
    "    - a training set of m_train images labeled as cat (y=1) or non-cat (y=0)\n",
    "    - a test set of m_test images labeled as cat or non-cat\n",
    "    - each image is of shape (num_px, num_px, 3) where 3 is for the 3 channels (RGB). Thus, each image is square (height = num_px) and (width = num_px).\n",
    "\n",
    "You will build a simple image-recognition algorithm that can correctly classify pictures as cat or non-cat.\n",
    "\n",
    "Let's get more familiar with the dataset. Load the data by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data (cat/non-cat)\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added \"_orig\" at the end of image datasets (train and test) because we are going to preprocess them. After preprocessing, we will end up with train_set_x and test_set_x (the labels train_set_y and test_set_y don't need any preprocessing).\n",
    "\n",
    "Each line of your train_set_x_orig and test_set_x_orig is an array representing an image. You can visualize an example by running the following code. Feel free also to change the `index` value and re-run to see other images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = [1], it's a 'cat' picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 25\n",
    "plt.imshow(train_set_x_orig[index])\n",
    "print (\"y = \" + str(train_set_y[:, index]) + \", it's a '\" + classes[np.squeeze(train_set_y[:, index])].decode(\"utf-8\") +  \"' picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many software bugs in deep learning come from having matrix/vector dimensions that don't fit. If you can keep your matrix/vector dimensions straight you will go a long way toward eliminating many bugs. \n",
    "\n",
    "<a name='ex-1'></a>\n",
    "### Exercise 1\n",
    "Find the values for:\n",
    "    - m_train (number of training examples)\n",
    "    - m_test (number of test examples)\n",
    "    - num_px (= height = width of a training image)\n",
    "Remember that `train_set_x_orig` is a numpy-array of shape (m_train, num_px, num_px, 3). For instance, you can access `m_train` by writing `train_set_x_orig.shape[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "921fe679a632ec7ec9963069fa405725",
     "grade": false,
     "grade_id": "cell-c4e7e9c1f174eb83",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 209\n",
      "Number of testing examples: m_test = 50\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "#(≈ 3 lines of code)\n",
    "# m_train = \n",
    "# m_test = \n",
    "# num_px = \n",
    "# YOUR CODE STARTS HERE\n",
    "m_train = train_set_x_orig.shape[0]\n",
    "m_test = test_set_x_orig.shape[0]\n",
    "num_px = train_set_x_orig[0].shape[0]\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_set_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_set_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output for m_train, m_test and num_px**: \n",
    "<table style=\"width:15%\">\n",
    "  <tr>\n",
    "    <td> m_train </td>\n",
    "    <td> 209 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>m_test</td>\n",
    "    <td> 50 </td> \n",
    "  </tr>\n",
    "  \n",
    "  <tr>\n",
    "    <td>num_px</td>\n",
    "    <td> 64 </td> \n",
    "  </tr>\n",
    "  \n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, you should now reshape images of shape (num_px, num_px, 3) in a numpy-array of shape (num_px $*$ num_px $*$ 3, 1). After this, our training (and test) dataset is a numpy-array where each column represents a flattened image. There should be m_train (respectively m_test) columns.\n",
    "\n",
    "<a name='ex-2'></a>\n",
    "### Exercise 2\n",
    "Reshape the training and test data sets so that images of size (num_px, num_px, 3) are flattened into single vectors of shape (num\\_px $*$ num\\_px $*$ 3, 1).\n",
    "\n",
    "A trick when you want to flatten a matrix X of shape (a,b,c,d) to a matrix X_flatten of shape (b$*$c$*$d, a) is to use: \n",
    "```python\n",
    "X_flatten = X.reshape(X.shape[0], -1).T      # X.T is the transpose of X\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5a2aa62bdd8c01450111b758ef159aec",
     "grade": false,
     "grade_id": "cell-0f43921062c34e50",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set_x_flatten shape: (12288, 209)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x_flatten shape: (12288, 50)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples\n",
    "#(≈ 2 lines of code)\n",
    "# train_set_x_flatten = ...\n",
    "# test_set_x_flatten = ...\n",
    "# YOUR CODE STARTS HERE\n",
    "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1).T\n",
    "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1).T\n",
    "\n",
    "# YOUR CODE ENDS HERE\n",
    "\n",
    "# Check that the first 10 pixels of the second image are in the correct place\n",
    "assert np.alltrue(train_set_x_flatten[0:10, 1] == [196, 192, 190, 193, 186, 182, 188, 179, 174, 213]), \"Wrong solution. Use (X.shape[0], -1).T.\"\n",
    "assert np.alltrue(test_set_x_flatten[0:10, 1] == [115, 110, 111, 137, 129, 129, 155, 146, 145, 159]), \"Wrong solution. Use (X.shape[0], -1).T.\"\n",
    "\n",
    "print (\"train_set_x_flatten shape: \" + str(train_set_x_flatten.shape))\n",
    "print (\"train_set_y shape: \" + str(train_set_y.shape))\n",
    "print (\"test_set_x_flatten shape: \" + str(test_set_x_flatten.shape))\n",
    "print (\"test_set_y shape: \" + str(test_set_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output**: \n",
    "\n",
    "<table style=\"width:35%\">\n",
    "  <tr>\n",
    "    <td>train_set_x_flatten shape</td>\n",
    "    <td> (12288, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>train_set_y shape</td>\n",
    "    <td>(1, 209)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_x_flatten shape</td>\n",
    "    <td>(12288, 50)</td> \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>test_set_y shape</td>\n",
    "    <td>(1, 50)</td> \n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent color images, the red, green and blue channels (RGB) must be specified for each pixel, and so the pixel value is actually a vector of three numbers ranging from 0 to 255.\n",
    "\n",
    "One common preprocessing step in machine learning is to center and standardize your dataset, meaning that you substract the mean of the whole numpy array from each example, and then divide each example by the standard deviation of the whole numpy array. But for picture datasets, it is simpler and more convenient and works almost as well to just divide every row of the dataset by 255 (the maximum value of a pixel channel).\n",
    "\n",
    "<!-- During the training of your model, you're going to multiply weights and add biases to some initial inputs in order to observe neuron activations. Then you backpropogate with the gradients to train the model. But, it is extremely important for each feature to have a similar range such that our gradients don't explode. You will see that more in detail later in the lectures. !--> \n",
    "\n",
    "Let's standardize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x = train_set_x_flatten / 255.\n",
    "test_set_x = test_set_x_flatten / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "    \n",
    "**What you need to remember:**\n",
    "\n",
    "Common steps for pre-processing a new dataset are:\n",
    "- Figure out the dimensions and shapes of the problem (m_train, m_test, num_px, ...)\n",
    "- Reshape the datasets such that each example is now a vector of size (num_px \\* num_px \\* 3, 1)\n",
    "- \"Standardize\" the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3 - General Architecture of the learning algorithm ##\n",
    "\n",
    "It's time to design a simple algorithm to distinguish cat images from non-cat images.\n",
    "\n",
    "You will build a Logistic Regression, using a Neural Network mindset. The following Figure explains why **Logistic Regression is actually a very simple Neural Network!**\n",
    "\n",
    "<img src=\"images/LogReg_kiank.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "**Mathematical expression of the algorithm**:\n",
    "\n",
    "For one example $x^{(i)}$:\n",
    "$$z^{(i)} = w^T x^{(i)} + b \\tag{1}$$\n",
    "$$\\hat{y}^{(i)} = a^{(i)} = sigmoid(z^{(i)})\\tag{2}$$ \n",
    "$$ \\mathcal{L}(a^{(i)}, y^{(i)}) =  - y^{(i)}  \\log(a^{(i)}) - (1-y^{(i)} )  \\log(1-a^{(i)})\\tag{3}$$\n",
    "\n",
    "The cost is then computed by summing over all training examples:\n",
    "$$ J = \\frac{1}{m} \\sum_{i=1}^m \\mathcal{L}(a^{(i)}, y^{(i)})\\tag{6}$$\n",
    "\n",
    "**Key steps**:\n",
    "In this exercise, you will carry out the following steps: \n",
    "    - Initialize the parameters of the model\n",
    "    - Learn the parameters for the model by minimizing the cost  \n",
    "    - Use the learned parameters to make predictions (on the test set)\n",
    "    - Analyse the results and conclude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4 - Building the parts of our algorithm ## \n",
    "\n",
    "The main steps for building a Neural Network are:\n",
    "1. Define the model structure (such as number of input features) \n",
    "2. Initialize the model's parameters\n",
    "3. Loop:\n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "\n",
    "You often build 1-3 separately and integrate them into one function we call `model()`.\n",
    "\n",
    "<a name='4-1'></a>\n",
    "### 4.1 - Helper functions\n",
    "\n",
    "<a name='ex-3'></a>\n",
    "### Exercise 3 - sigmoid\n",
    "Using your code from \"Python Basics\", implement `sigmoid()`. As you've seen in the figure above, you need to compute $sigmoid(z) = \\frac{1}{1 + e^{-z}}$ for $z = w^T x + b$ to make predictions. Use np.exp()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "239ab1cf1028b721fd14f31b8103c40d",
     "grade": false,
     "grade_id": "cell-520521c430352f3b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Compute the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- A scalar or numpy array of any size.\n",
    "\n",
    "    Return:\n",
    "    s -- sigmoid(z)\n",
    "    \"\"\"\n",
    "\n",
    "    #(≈ 1 line of code)\n",
    "    # s = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0483e6820669111a9c5914d8b24bc315",
     "grade": true,
     "grade_id": "cell-30ea3151cab9c491",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid([0, 2]) = [0.5        0.88079708]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid([0, 2]) = \" + str(sigmoid(np.array([0,2]))))\n",
    "\n",
    "sigmoid_test(sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62245933 0.5        0.88079708]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([0.5, 0, 2.0])\n",
    "output = sigmoid(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-2'></a>\n",
    "### 4.2 - Initializing parameters\n",
    "\n",
    "<a name='ex-4'></a>\n",
    "### Exercise 4 - initialize_with_zeros\n",
    "Implement parameter initialization in the cell below. You have to initialize w as a vector of zeros. If you don't know what numpy function to use, look up np.zeros() in the Numpy library's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c4a37e375a85ddab7274a33abf46bb7c",
     "grade": false,
     "grade_id": "cell-befa9335e479864e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_with_zeros\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    \"\"\"\n",
    "    This function creates a vector of zeros of shape (dim, 1) for w and initializes b to 0.\n",
    "    \n",
    "    Argument:\n",
    "    dim -- size of the w vector we want (or number of parameters in this case)\n",
    "    \n",
    "    Returns:\n",
    "    w -- initialized vector of shape (dim, 1)\n",
    "    b -- initialized scalar (corresponds to the bias) of type float\n",
    "    \"\"\"\n",
    "    \n",
    "    # (≈ 2 lines of code)\n",
    "    # w = ...\n",
    "    # b = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0.\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a4c13b0eafa46ca94de21b41faea8c58",
     "grade": true,
     "grade_id": "cell-a3b6699f145f3a3f",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.]\n",
      " [0.]]\n",
      "b = 0.0\n",
      "\u001b[92mFirst test passed!\n",
      "\u001b[92mSecond test passed!\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "w, b = initialize_with_zeros(dim)\n",
    "\n",
    "assert type(b) == float\n",
    "print (\"w = \" + str(w))\n",
    "print (\"b = \" + str(b))\n",
    "\n",
    "initialize_with_zeros_test_1(initialize_with_zeros)\n",
    "initialize_with_zeros_test_2(initialize_with_zeros)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-3'></a>\n",
    "### 4.3 - Forward and Backward propagation\n",
    "\n",
    "Now that your parameters are initialized, you can do the \"forward\" and \"backward\" propagation steps for learning the parameters.\n",
    "\n",
    "<a name='ex-5'></a>\n",
    "### Exercise 5 - propagate\n",
    "Implement a function `propagate()` that computes the cost function and its gradient.\n",
    "\n",
    "**Hints**:\n",
    "\n",
    "Forward Propagation:\n",
    "- You get X\n",
    "- You compute $A = \\sigma(w^T X + b) = (a^{(1)}, a^{(2)}, ..., a^{(m-1)}, a^{(m)})$\n",
    "- You calculate the cost function: $J = -\\frac{1}{m}\\sum_{i=1}^{m}(y^{(i)}\\log(a^{(i)})+(1-y^{(i)})\\log(1-a^{(i)}))$\n",
    "\n",
    "Here are the two formulas you will be using: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X(A-Y)^T\\tag{7}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (a^{(i)}-y^{(i)})\\tag{8}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8552b2c9cff2b5fa537fab9f98a6e4da",
     "grade": false,
     "grade_id": "cell-11af17e28077b3d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: propagate\n",
    "\n",
    "def propagate(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function and its gradient for the propagation explained above\n",
    "\n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat) of size (1, number of examples)\n",
    "\n",
    "    Return:\n",
    "    grads -- dictionary containing the gradients of the weights and bias\n",
    "            (dw -- gradient of the loss with respect to w, thus same shape as w)\n",
    "            (db -- gradient of the loss with respect to b, thus same shape as b)\n",
    "    cost -- negative log-likelihood cost for logistic regression\n",
    "    \n",
    "    Tips:\n",
    "    - Write your code step by step for the propagation. np.log(), np.dot()\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # FORWARD PROPAGATION (FROM X TO COST)\n",
    "    #(≈ 2 lines of code)\n",
    "    # compute activation\n",
    "    # A = ...\n",
    "    # compute cost by using np.dot to perform multiplication. \n",
    "    # And don't use loops for the sum.\n",
    "    # cost = ...                                \n",
    "    # YOUR CODE STARTS HERE\n",
    "    z = np.dot(w.T,X) + b\n",
    "    a = sigmoid(z)\n",
    "    cost = (-1/m) * (np.dot(Y,np.log(a).T) + np.dot((1-Y),np.log(1-a).T))\n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    # BACKWARD PROPAGATION (TO FIND GRAD)\n",
    "    #(≈ 2 lines of code)\n",
    "    # dw = ...\n",
    "    # db = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    dw = np.dot(X,(a - Y).T) * (1/m)\n",
    "    db = np.sum(a-Y)/m\n",
    "    # YOUR CODE ENDS HERE\n",
    "    cost = np.squeeze(np.array(cost))\n",
    "\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads, cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8a1a4b1ff8d70ac609d721490b4d826",
     "grade": true,
     "grade_id": "cell-d1594d75b61dd554",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw = [[ 0.25071532]\n",
      " [-0.06604096]]\n",
      "db = -0.12500404500439652\n",
      "cost = 0.15900537707692405\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "w =  np.array([[1.], [2]])\n",
    "b = 1.5\n",
    "X = np.array([[1., -2., -1.], [3., 0.5, -3.2]])\n",
    "Y = np.array([[1, 1, 0]])\n",
    "grads, cost = propagate(w, b, X, Y)\n",
    "\n",
    "assert type(grads[\"dw\"]) == np.ndarray\n",
    "assert grads[\"dw\"].shape == (2, 1)\n",
    "assert type(grads[\"db\"]) == np.float64\n",
    "\n",
    "\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print (\"cost = \" + str(cost))\n",
    "\n",
    "propagate_test(propagate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output**\n",
    "\n",
    "```\n",
    "dw = [[ 0.25071532]\n",
    " [-0.06604096]]\n",
    "db = -0.1250040450043965\n",
    "cost = 0.15900537707692405\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='4-4'></a>\n",
    "### 4.4 - Optimization\n",
    "- You have initialized your parameters.\n",
    "- You are also able to compute a cost function and its gradient.\n",
    "- Now, you want to update the parameters using gradient descent.\n",
    "\n",
    "<a name='ex-6'></a>\n",
    "### Exercise 6 - optimize\n",
    "Write down the optimization function. The goal is to learn $w$ and $b$ by minimizing the cost function $J$. For a parameter $\\theta$, the update rule is $ \\theta = \\theta - \\alpha \\text{ } d\\theta$, where $\\alpha$ is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d9b4c1a780bf141c8eb48e06cbb494",
     "grade": false,
     "grade_id": "cell-616d6883e807448d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: optimize\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False):\n",
    "    \"\"\"\n",
    "    This function optimizes w and b by running a gradient descent algorithm\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of shape (num_px * num_px * 3, number of examples)\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat), of shape (1, number of examples)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- True to print the loss every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    params -- dictionary containing the weights w and bias b\n",
    "    grads -- dictionary containing the gradients of the weights and bias with respect to the cost function\n",
    "    costs -- list of all the costs computed during the optimization, this will be used to plot the learning curve.\n",
    "    \n",
    "    Tips:\n",
    "    You basically need to write down two steps and iterate through them:\n",
    "        1) Calculate the cost and the gradient for the current parameters. Use propagate().\n",
    "        2) Update the parameters using gradient descent rule for w and b.\n",
    "    \"\"\"\n",
    "    \n",
    "    w = copy.deepcopy(w)\n",
    "    b = copy.deepcopy(b)\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        # (≈ 1 lines of code)\n",
    "        # Cost and gradient calculation \n",
    "        # grads, cost = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        grads, cost = propagate(w,b, X,Y)\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Retrieve derivatives from grads\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        \n",
    "        # update rule (≈ 2 lines of code)\n",
    "        # w = ...\n",
    "        # b = ...\n",
    "        # YOUR CODE STARTS HERE\n",
    "        w=w - learning_rate * dw\n",
    "        b = b- learning_rate*db\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "        \n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "            # Print the cost every 100 training iterations\n",
    "            if print_cost:\n",
    "                print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "    \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b65a5c90f86a990614156e41f64b4678",
     "grade": true,
     "grade_id": "cell-8e3d43fbb82a8901",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0.80956046]\n",
      " [2.0508202 ]]\n",
      "b = 1.5948713189708588\n",
      "dw = [[ 0.17860505]\n",
      " [-0.04840656]]\n",
      "db = -0.08888460336847771\n",
      "Costs = [array(0.15900538)]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "params, grads, costs = optimize(w, b, X, Y, num_iterations=100, learning_rate=0.009, print_cost=False)\n",
    "\n",
    "print (\"w = \" + str(params[\"w\"]))\n",
    "print (\"b = \" + str(params[\"b\"]))\n",
    "print (\"dw = \" + str(grads[\"dw\"]))\n",
    "print (\"db = \" + str(grads[\"db\"]))\n",
    "print(\"Costs = \" + str(costs))\n",
    "\n",
    "optimize_test(optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='ex-7'></a>\n",
    "### Exercise 7 - predict\n",
    "The previous function will output the learned w and b. We are able to use w and b to predict the labels for a dataset X. Implement the `predict()` function. There are two steps to computing predictions:\n",
    "\n",
    "1. Calculate $\\hat{Y} = A = \\sigma(w^T X + b)$\n",
    "\n",
    "2. Convert the entries of a into 0 (if activation <= 0.5) or 1 (if activation > 0.5), stores the predictions in a vector `Y_prediction`. If you wish, you can use an `if`/`else` statement in a `for` loop (though there is also a way to vectorize this). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e56419b97ebf382a8f93ac2873988887",
     "grade": false,
     "grade_id": "cell-d6f924f49c51dc2f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: predict\n",
    "\n",
    "def predict(w, b, X):\n",
    "    '''\n",
    "    Predict whether the label is 0 or 1 using learned logistic regression parameters (w, b)\n",
    "    \n",
    "    Arguments:\n",
    "    w -- weights, a numpy array of size (num_px * num_px * 3, 1)\n",
    "    b -- bias, a scalar\n",
    "    X -- data of size (num_px * num_px * 3, number of examples)\n",
    "    \n",
    "    Returns:\n",
    "    Y_prediction -- a numpy array (vector) containing all predictions (0/1) for the examples in X\n",
    "    '''\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Compute vector \"A\" predicting the probabilities of a cat being present in the picture\n",
    "    #(≈ 1 line of code)\n",
    "    # A = ...\n",
    "    # YOUR CODE STARTS HERE\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        \n",
    "        # Convert probabilities A[0,i] to actual predictions p[0,i]\n",
    "        #(≈ 4 lines of code)\n",
    "        # if A[0, i] > ____ :\n",
    "        #     Y_prediction[0,i] = \n",
    "        # else:\n",
    "        #     Y_prediction[0,i] = \n",
    "        # YOUR CODE STARTS HERE\n",
    "        if A[0,i] >=0.5:\n",
    "            Y_prediction[0,i] = 1\n",
    "        else:\n",
    "            Y_prediction[0,i]=0\n",
    "        \n",
    "        # YOUR CODE ENDS HERE\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3ea12608f15798d542a07c1bc9f561b",
     "grade": true,
     "grade_id": "cell-90b1fb967269548c",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions = [[1. 1. 0.]]\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "w = np.array([[0.1124579], [0.23106775]])\n",
    "b = -0.3\n",
    "X = np.array([[1., -1.1, -3.2],[1.2, 2., 0.1]])\n",
    "print (\"predictions = \" + str(predict(w, b, X)))\n",
    "\n",
    "predict_test(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What to remember:**\n",
    "    \n",
    "You've implemented several functions that:\n",
    "- Initialize (w,b)\n",
    "- Optimize the loss iteratively to learn parameters (w,b):\n",
    "    - Computing the cost and its gradient \n",
    "    - Updating the parameters using gradient descent\n",
    "- Use the learned (w,b) to predict the labels for a given set of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5 - Merge all functions into a model ##\n",
    "\n",
    "You will now see how the overall model is structured by putting together all the building blocks (functions implemented in the previous parts) together, in the right order.\n",
    "\n",
    "<a name='ex-8'></a>\n",
    "### Exercise 8 - model\n",
    "Implement the model function. Use the following notation:\n",
    "    - Y_prediction_test for your predictions on the test set\n",
    "    - Y_prediction_train for your predictions on the train set\n",
    "    - parameters, grads, costs for the outputs of optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b62adfb8f5a0f5bb5aa6798c3c5df66d",
     "grade": false,
     "grade_id": "cell-6dcba5967c4cbf8c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5, print_cost=False):\n",
    "    \"\"\"\n",
    "    Builds the logistic regression model by calling the function you've implemented previously\n",
    "    \n",
    "    Arguments:\n",
    "    X_train -- training set represented by a numpy array of shape (num_px * num_px * 3, m_train)\n",
    "    Y_train -- training labels represented by a numpy array (vector) of shape (1, m_train)\n",
    "    X_test -- test set represented by a numpy array of shape (num_px * num_px * 3, m_test)\n",
    "    Y_test -- test labels represented by a numpy array (vector) of shape (1, m_test)\n",
    "    num_iterations -- hyperparameter representing the number of iterations to optimize the parameters\n",
    "    learning_rate -- hyperparameter representing the learning rate used in the update rule of optimize()\n",
    "    print_cost -- Set to True to print the cost every 100 iterations\n",
    "    \n",
    "    Returns:\n",
    "    d -- dictionary containing information about the model.\n",
    "    \"\"\"\n",
    "    # (≈ 1 line of code)   \n",
    "    # initialize parameters with zeros\n",
    "    # and use the \"shape\" function to get the first dimension of X_train\n",
    "    # w, b = ...\n",
    "    \n",
    "    #(≈ 1 line of code)\n",
    "    # Gradient descent \n",
    "    # params, grads, costs = ...\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"params\"\n",
    "    # w = ...\n",
    "    # b = ...\n",
    "    \n",
    "    # Predict test/train set examples (≈ 2 lines of code)\n",
    "    # Y_prediction_test = ...\n",
    "    # Y_prediction_train = ...\n",
    "    \n",
    "    # YOUR CODE STARTS HERE\n",
    "    w,b = initialize_with_zeros(X_train.shape[0])\n",
    "    #     grads, cost = propagate(w, b, X_train, Y_train)\n",
    "    params, grads, costs = optimize(w, b, X_train, Y_train, num_iterations=num_iterations, learning_rate=learning_rate)\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    Y_prediction_test = predict(w, b, X_test)\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    \n",
    "    # YOUR CODE ENDS HERE\n",
    "\n",
    "    # Print train/test Errors\n",
    "    if print_cost:\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"w\" : w, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b468bc5ddf6ecc5c7dbcb9a02cfe0216",
     "grade": true,
     "grade_id": "cell-4170e070f3cde17e",
     "locked": true,
     "points": 10,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n",
      "0.6909490977063018\n",
      "0.68876715622128\n",
      "0.6866012114471467\n",
      "0.6844511196826287\n",
      "0.6823167381945483\n",
      "0.6801979252286899\n",
      "0.6780945400199206\n",
      "0.6760064428015813\n",
      "0.6739334948141705\n",
      "0.6718755583133359\n",
      "0.6698324965771959\n",
      "0.6678041739130095\n",
      "0.6657904556632107\n",
      "0.6637912082108302\n",
      "0.6618062989843179\n",
      "0.6598355964617889\n",
      "0.6578789701747101\n",
      "0.6559362907110416\n",
      "0.6540074297178562\n",
      "0.6520922599034492\n",
      "0.6501906550389612\n",
      "0.6483024899595237\n",
      "0.6464276405649514\n",
      "0.6445659838199926\n",
      "0.6427173977541565\n",
      "0.6408817614611295\n",
      "0.6390589550978029\n",
      "0.6372488598829185\n",
      "0.6354513580953541\n",
      "0.6336663330720596\n",
      "0.6318936692056589\n",
      "0.6301332519417322\n",
      "0.6283849677757907\n",
      "0.6266487042499593\n",
      "0.624924349949378\n",
      "0.6232117944983353\n",
      "0.6215109285561481\n",
      "0.6198216438127947\n",
      "0.6181438329843209\n",
      "0.6164773898080199\n",
      "0.6148222090374095\n",
      "0.6131781864370045\n",
      "0.611545218776905\n",
      "0.6099232038272054\n",
      "0.6083120403522356\n",
      "0.6067116281046432\n",
      "0.6051218678193263\n",
      "0.6035426612072264\n",
      "0.6019739109489892\n",
      "\u001b[92mAll tests passed!\n"
     ]
    }
   ],
   "source": [
    "from public_tests import *\n",
    "\n",
    "model_test(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you pass all the tests, run the following cell to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6931471805599453\n",
      "0.7410294145065184\n",
      "0.753153581886211\n",
      "0.8667086956701202\n",
      "0.7685635006608347\n",
      "0.897014473644793\n",
      "0.7556132280568213\n",
      "0.880436642683987\n",
      "0.7514852682041282\n",
      "0.8771330533999598\n",
      "0.7449403578103343\n",
      "0.869479030571014\n",
      "0.7395380761496433\n",
      "0.8631813827864872\n",
      "0.7341140373099903\n",
      "0.8564988745006687\n",
      "0.728988316666542\n",
      "0.8499947121719623\n",
      "0.7240300591410962\n",
      "0.843519150240876\n",
      "0.7192489303106331\n",
      "0.8371297668639591\n",
      "0.7146178461453454\n",
      "0.8308196474365936\n",
      "0.7101237125685044\n",
      "0.8245968156414775\n",
      "0.7057525912197258\n",
      "0.818462789308895\n",
      "0.7014932393013824\n",
      "0.8124189543586329\n",
      "0.6973357819554408\n",
      "0.8064653562757486\n",
      "0.6932717128504406\n",
      "0.8006013474032808\n",
      "0.6892936205327379\n",
      "0.7948256977270332\n",
      "0.6853950268137255\n",
      "0.78913677370817\n",
      "0.6815702381349416\n",
      "0.7835326559229571\n",
      "0.677814225655342\n",
      "0.7780112344915429\n",
      "0.6741225251755734\n",
      "0.7725702816054895\n",
      "0.6704911541755104\n",
      "0.7672075072052832\n",
      "0.6669165427749885\n",
      "0.7619206012194385\n",
      "0.6633954761707312\n",
      "0.7567072652986896\n",
      "0.6599250465088031\n",
      "0.7515652363088827\n",
      "0.6565026125262358\n",
      "0.7464923033757679\n",
      "0.6531257655972147\n",
      "0.7414863198969832\n",
      "0.6497923010676048\n",
      "0.7365452116406304\n",
      "0.6465001939645266\n",
      "0.73166698181618\n",
      "0.643247578333392\n",
      "0.7268497138186595\n",
      "0.6400327295898607\n",
      "0.72209157220057\n",
      "0.6368540493842914\n",
      "0.7173908023096313\n",
      "0.6337100525659516\n",
      "0.7127457289378907\n",
      "0.630599355907401\n",
      "0.7081547542540252\n",
      "0.6275206683091039\n",
      "0.70361635523192\n",
      "0.6244727822530355\n",
      "0.6991290807417755\n",
      "0.6214545663138488\n",
      "0.6946915484326741\n",
      "0.6184649585687425\n",
      "0.69030244150581\n",
      "0.6155029607738625\n",
      "0.6859605054539334\n",
      "0.6125676331969916\n",
      "0.6816645448237989\n",
      "0.609658090014292\n",
      "0.6774134200435374\n",
      "0.6067734951937223\n",
      "0.6732060443451459\n",
      "0.6039130588000033\n",
      "0.6690413808030821\n",
      "0.6010760336661553\n",
      "0.6649184395027571\n",
      "0.5982617123850421\n",
      "0.6608362748471476\n",
      "0.5954694245813507\n",
      "0.6567939830054661\n",
      "0.5926985344302729\n",
      "0.6527906995045833\n",
      "0.5899484383940269\n",
      "0.6488255969614724\n",
      "0.587218563151448\n",
      "0.6448978829531701\n",
      "0.5845083636993087\n",
      "0.641006798019497\n",
      "0.5818173216069348\n",
      "0.637151613792928\n",
      "0.5791449434081318\n",
      "0.6333316312494625\n",
      "0.5764907591165143\n",
      "0.6295461790740619\n",
      "0.5738543208521087\n",
      "0.6257946121341076\n",
      "0.5712352015686086\n",
      "0.6220763100543738\n",
      "0.5686329938719571\n",
      "0.6183906758871472\n",
      "0.5660473089220476\n",
      "0.6147371348713364\n",
      "0.5634777754102926\n",
      "0.6111151332746846\n",
      "0.5609240386066406\n",
      "0.6075241373134934\n",
      "0.5583857594703387\n",
      "0.6039636321445838\n",
      "0.5558626138193703\n",
      "0.6004331209245504\n",
      "0.553354291554036\n",
      "0.5969321239316909\n",
      "0.5508604959306289\n",
      "0.5934601777463145\n",
      "0.5483809428815709\n",
      "0.5900168344854453\n",
      "0.545915360378744\n",
      "0.5866016610882367\n",
      "0.5434634878370808\n",
      "0.5832142386486988\n",
      "0.5410250755557533\n",
      "0.5798541617926044\n",
      "0.5385998841945687\n",
      "0.5765210380956987\n",
      "0.5361876842833908\n",
      "0.5732144875405625\n",
      "0.5337882557626193\n",
      "0.5699341420097105\n",
      "0.5314013875529302\n",
      "0.5666796448126955\n",
      "0.5290268771526502\n",
      "0.5634506502451881\n",
      "0.5266645302612729\n",
      "0.5602468231781691\n",
      "0.5243141604277675\n",
      "0.5570678386755334\n",
      "0.521975588722439\n",
      "0.5539133816385551\n",
      "0.519648643431216\n",
      "0.5507831464757946\n",
      "0.5173331597713365\n",
      "0.547676836797164\n",
      "0.5150289796274969\n",
      "0.5445941651309734\n",
      "0.5127359513076121\n",
      "0.5415348526629058\n",
      "0.5104539293174177\n",
      "0.5384986289959504\n",
      "0.5081827741532154\n",
      "0.5354852319304387\n",
      "0.5059223521121375\n",
      "0.5324944072634062\n",
      "0.5036725351193723\n",
      "0.5295259086065933\n",
      "0.501433200571856\n",
      "0.5265794972224744\n",
      "0.4992042311980022\n",
      "0.5236549418777877\n",
      "0.49698551493309834\n",
      "0.5207520187141108\n",
      "0.4947769448100626\n",
      "0.5178705111350965\n",
      "0.4925784188653097\n",
      "0.5150102097100575\n",
      "0.4903898400595383\n",
      "0.5121709120936565\n",
      "0.4882111162133116\n",
      "0.5093524229615245\n",
      "0.48604215995735994\n",
      "0.5065545539617036\n",
      "0.48388288869760165\n",
      "0.5037771236818703\n",
      "0.48173322459493667\n",
      "0.5010199576323695\n",
      "0.4795930945599333\n",
      "0.4982828882451569\n",
      "0.4774624302625983\n",
      "0.4955657548888152\n",
      "0.4753411681574844\n",
      "0.49286840389987974\n",
      "0.47322924952446294\n",
      "0.4901906886307844\n",
      "0.47112662052556814\n",
      "0.4875324695148093\n",
      "0.469033232278386\n",
      "0.4848936141484849\n",
      "0.46694904094655476\n",
      "0.48227399739198706\n",
      "0.46487400784801647\n",
      "0.47967350148813304\n",
      "0.46280809958175345\n",
      "0.47709201620066766\n",
      "0.4607512881738306\n",
      "0.4745294389726099\n",
      "0.45870355124366385\n",
      "0.4719856751055087\n",
      "0.4566648721915241\n",
      "0.4694606379605423\n",
      "0.4546352404083988\n",
      "0.46695424918246775\n",
      "0.4526146515094254\n",
      "0.46446643894751777\n",
      "0.4506031075922238\n",
      "0.4619971462364038\n",
      "0.44860061752155944\n",
      "0.45954631913366956\n",
      "0.4466071972418735\n",
      "0.45711391515469313\n",
      "0.4446228701193258\n",
      "0.4546999016016996\n",
      "0.4426476673150915\n",
      "0.45230425595018525\n",
      "0.440681628191754\n",
      "0.4499269662671886\n",
      "0.4387248007547159\n",
      "0.4475680316628426\n",
      "0.4367772421306287\n",
      "0.44522746277663805\n",
      "0.434839019084887\n",
      "0.4429052822997671\n",
      "0.43291020858027174\n",
      "0.4406015255348335\n",
      "0.43099089837881727\n",
      "0.43831624099407634\n",
      "0.4290811876889354\n",
      "0.4360494910370568\n",
      "0.4271811878597369\n",
      "0.43380135254848395\n",
      "0.4252910231243292\n",
      "0.4315719176565032\n",
      "0.4234108313936333\n",
      "0.4293612944913042\n",
      "0.42154076510192434\n",
      "0.42716960798331866\n",
      "0.4196809921048515\n",
      "0.42499700069954927\n",
      "0.41783169663009556\n",
      "0.422843633715662\n",
      "0.4159930802800587\n",
      "0.4207096875203672\n",
      "0.4141653630850181\n",
      "0.41859536294728333\n",
      "0.4123487846039702\n",
      "0.416500882127863\n",
      "0.41054360506891785\n",
      "0.41442648945706306\n",
      "0.4087501065665542\n",
      "0.41237245256118393\n",
      "0.40696859424913157\n",
      "0.41033906325467534\n",
      "0.4051993975637267\n",
      "0.40832663846965433\n",
      "0.403442871486063\n",
      "0.4063355211383761\n",
      "0.4016993977414896\n",
      "0.40436608100490584\n",
      "0.3999693859915879\n",
      "0.40241871533775064\n",
      "0.39825327496014945\n",
      "0.4004938495102033\n",
      "0.39655153346691663\n",
      "0.3985919374096682\n",
      "0.39486466133148557\n",
      "0.3967134616312997\n",
      "0.393193190103184\n",
      "0.3948589334050027\n",
      "0.3915376835655914\n",
      "0.39302889219833875\n",
      "0.3898987379567916\n",
      "0.3912239049313531\n",
      "0.3882769818386255\n",
      "0.3894445647330716\n",
      "0.38667307554038083\n",
      "0.3876914891637539\n",
      "0.38508771009489395\n",
      "0.38596531782241084\n",
      "0.38352160557840587\n",
      "0.3842667092561593\n",
      "0.38197550876031106\n",
      "0.38259633708737956\n",
      "0.3804501899658872\n",
      "0.38095488527715726\n",
      "0.3789464390550751\n",
      "0.3793430424500111\n",
      "0.3774650604243752\n",
      "0.37776149521638075\n",
      "0.37600686694802077\n",
      "0.37621092044673016\n",
      "0.37457267278992734\n",
      "0.37469197647530555\n",
      "0.37316328504057084\n",
      "0.3732052932433021\n",
      "0.3717794941639073\n",
      "0.37175146143088006\n",
      "0.37042206327935184\n",
      "0.37033102067512946\n",
      "0.36909171635294324\n",
      "0.3689444470261167\n",
      "0.36778912542970976\n",
      "0.3675921398541885\n",
      "0.36651489710468893\n",
      "0.36627440848651155\n",
      "0.36526955850080733\n",
      "0.3649914589161128\n",
      "0.36405354309454374\n",
      "0.3637433809882394\n",
      "0.3628671768004665\n",
      "0.3625301365215135\n",
      "0.36171066478781344\n",
      "0.36135154885938003\n",
      "0.36058407954990895\n",
      "0.3602072943647402\n",
      "0.35948735077372707\n",
      "0.3590968963618438\n",
      "0.35842025755590257\n",
      "0.3580197219899161\n",
      "0.35738242347768184\n",
      "0.3569749823599135\n",
      "0.35637331498127534\n",
      "0.3559617362990389\n",
      "0.3553922433832199\n",
      "0.3549788978301164\n",
      "0.3544383707194073\n",
      "0.35402524737087143\n",
      "0.3535107194478467\n",
      "0.3530994464610893\n",
      "0.35260818584905296\n",
      "0.352200055645648\n",
      "0.3517295567731742\n",
      "0.3513255549722942\n",
      "0.35087352920241854\n",
      "0.35047436641871327\n",
      "0.3500387319421303\n",
      "0.34964487745657047\n",
      "0.3492237486376544\n",
      "0.3488354649004969\n",
      "0.34842714124748764\n",
      "0.34804451818309234\n",
      "0.34764747309219\n",
      "0.34727046124361083\n",
      "0.34688333064388505\n",
      "0.3465117723137941\n",
      "0.3461333433182681\n",
      "0.3457670010205013\n",
      "0.3453962006704071\n",
      "0.3450347823891382\n",
      "0.3446706665642172\n",
      "0.34431384751029614\n",
      "0.3439555900683577\n",
      "0.34360303081006566\n",
      "0.3432499130132741\n",
      "0.34290127402909465\n",
      "0.34255267431155667\n",
      "0.3422076271560245\n",
      "0.3418630112858342\n",
      "0.34152124667020156\n",
      "0.34118015835779547\n",
      "0.34084139152288634\n",
      "0.3405034435251989\n",
      "0.3401674173254017\n",
      "0.33983228309107555\n",
      "0.33949876921950983\n",
      "0.3391661751139331\n",
      "0.338834973884711\n",
      "0.3385046920249678\n",
      "0.3381756310953305\n",
      "0.33784747281466143\n",
      "0.33752040518390736\n",
      "0.3371942151336296\n",
      "0.33686901670298997\n",
      "0.3365446675878064\n",
      "0.33622123451072916\n",
      "0.3358986224417361\n",
      "0.3355768684412892\n",
      "0.3352559088804744\n",
      "0.33493576266251984\n",
      "0.33461638692366746\n",
      "0.3342977897727744\n",
      "0.3339799420368132\n",
      "0.3336628456473471\n",
      "0.3333464804454546\n",
      "0.3330308450129771\n",
      "0.3327159251281503\n",
      "0.33240171770572424\n",
      "0.3320882124429035\n",
      "0.33177540555235874\n",
      "0.3314632893282512\n",
      "0.3311518598069664\n",
      "0.3308411110131455\n",
      "0.3305310390714592\n",
      "0.33022163916774705\n",
      "0.3299129076297666\n",
      "0.32960484042900395\n",
      "0.32929743412947654\n",
      "0.3289906852392287\n",
      "0.32868459055055926\n",
      "0.32837914694183495\n",
      "0.3280743514076863\n",
      "0.3277702010851469\n",
      "0.32746669313988536\n",
      "0.3271638248921545\n",
      "0.32686159364838524\n",
      "0.32655999686081055\n",
      "0.3262590319501482\n",
      "0.32595869646568315\n",
      "0.3256589879205829\n",
      "0.3253599039373209\n",
      "0.3250614421041722\n",
      "0.3247636001004829\n",
      "0.3244663755762174\n",
      "0.3241697662564422\n",
      "0.3238737698426166\n",
      "0.32357838409791456\n",
      "0.32328360676763923\n",
      "0.32298943564787813\n",
      "0.32269586852207993\n",
      "0.3224029032157023\n",
      "0.32211053754610663\n",
      "0.32181876936569426\n",
      "0.3215275965225911\n",
      "0.3212370168944657\n",
      "0.32094702835785255\n",
      "0.3206576288145097\n",
      "0.3203688161675973\n",
      "0.3200805883421129\n",
      "0.3197929432664718\n",
      "0.31950587888827275\n",
      "0.3192193931601114\n",
      "0.3189334840516853\n",
      "0.31864814953890636\n",
      "0.318363387613153\n",
      "0.31807919627294196\n",
      "0.3177955735309667\n",
      "0.3175125174077466\n",
      "0.3172300259369556\n",
      "0.31694809716059336\n",
      "0.31666672913299915\n",
      "0.3163859199171893\n",
      "0.3161056675878645\n",
      "0.3158259702286378\n",
      "0.3155468259342747\n",
      "0.31526823280859867\n",
      "0.3149901889661485\n",
      "0.3147126925305976\n",
      "0.3144357416359706\n",
      "0.31415933442545096\n",
      "0.3138834690522661\n",
      "0.313608143678786\n",
      "0.31333335647716076\n",
      "0.31305910562863826\n",
      "0.31278538932401545\n",
      "0.3125122057631206\n",
      "0.3122395531551266\n",
      "0.31196742971815455\n",
      "0.3116958336794862\n",
      "0.3114247632752578\n",
      "0.3111542167505978\n",
      "0.31088419235938736\n",
      "0.31061468836434425\n",
      "0.31034570303683257\n",
      "0.3100772346569064\n",
      "0.3098092815131568\n",
      "0.30954184190272704\n",
      "0.3092749141311857\n",
      "0.309008496512522\n",
      "0.30874258736903903\n",
      "0.3084771850313342\n",
      "0.3082122878382071\n",
      "0.3079478941366298\n",
      "0.30768400228166626\n",
      "0.30742061063643483\n",
      "0.3071577175720361\n",
      "0.306895321467511\n",
      "0.3066334207097741\n",
      "0.3063720136935693\n",
      "0.3061110988214077\n",
      "0.3058506745035208\n",
      "0.30559073915780266\n",
      "0.3053312912097618\n",
      "0.30507232909246595\n",
      "0.30481385124649407\n",
      "0.3045558561198827\n",
      "0.3042983421680782\n",
      "0.3040413078538852\n",
      "0.3037847516474191\n",
      "0.3035286720260554\n",
      "0.30327306747438293\n",
      "0.30301793648415537\n",
      "0.3027632775542439\n",
      "0.30250908919059066\n",
      "0.3022553699061614\n",
      "0.30200211822090045\n",
      "0.3017493326616845\n",
      "0.3014970117622774\n",
      "0.30124515406328556\n",
      "0.30099375811211365\n",
      "0.3007428224629202\n",
      "0.3004923456765745\n",
      "0.3002423263206134\n",
      "0.2999927629691979\n",
      "0.2997436542030715\n",
      "0.2994949986095177\n",
      "0.2992467947823189\n",
      "0.29899904132171434\n",
      "0.2987517368343596\n",
      "0.2985048799332863\n",
      "0.29825846923786115\n",
      "0.29801250337374696\n",
      "0.2977669809728625\n",
      "0.29752190067334355\n",
      "0.29727726111950403\n",
      "0.2970330609617978\n",
      "0.2967892988567798\n",
      "0.296545973467069\n",
      "0.2963030834613101\n",
      "0.2960606275141371\n",
      "0.29581860430613577\n",
      "0.29557701252380725\n",
      "0.2953358508595321\n",
      "0.2950951180115338\n",
      "0.29485481268384356\n",
      "0.29461493358626434\n",
      "0.2943754794343363\n",
      "0.2941364489493019\n",
      "0.293897840858071\n",
      "0.2936596538931872\n",
      "0.29342188679279324\n",
      "0.29318453830059804\n",
      "0.29294760716584234\n",
      "0.2927110921432665\n",
      "0.2924749919930772\n",
      "0.2922393054809146\n",
      "0.29200403137782055\n",
      "0.29176916846020573\n",
      "0.2915347155098185\n",
      "0.2913006713137132\n",
      "0.2910670346642181\n",
      "0.2908338043589054\n",
      "0.2906009792005594\n",
      "0.29036855799714656\n",
      "0.2901365395617847\n",
      "0.28990492271271295\n",
      "0.28967370627326217\n",
      "0.2894428890718248\n",
      "0.2892124699418256\n",
      "0.2889824477216925\n",
      "0.2887528212548276\n",
      "0.2885235893895781\n",
      "0.28829475097920837\n",
      "0.28806630488187074\n",
      "0.2878382499605783\n",
      "0.28761058508317616\n",
      "0.2873833091223143\n",
      "0.2871564209554198\n",
      "0.2869299194646698\n",
      "0.286703803536964\n",
      "0.2864780720638982\n",
      "0.2862527239417374\n",
      "0.28602775807138925\n",
      "0.28580317335837785\n",
      "0.2855789687128181\n",
      "0.2853551430493887\n",
      "0.28513169528730753\n",
      "0.28490862435030545\n",
      "0.2846859291666015\n",
      "0.28446360866887727\n",
      "0.28424166179425187\n",
      "0.2840200874842577\n",
      "0.2837988846848155\n",
      "0.28357805234620975\n",
      "0.2833575894230648\n",
      "0.2831374948743205\n",
      "0.28291776766320836\n",
      "0.2826984067572278\n",
      "0.28247941112812275\n",
      "0.2822607797518581\n",
      "0.28204251160859617\n",
      "0.2818246056826746\n",
      "0.28160706096258215\n",
      "0.281389876440937\n",
      "0.2811730511144638\n",
      "0.280956583983971\n",
      "0.28074047405432906\n",
      "0.2805247203344479\n",
      "0.2803093218372554\n",
      "0.2800942775796751\n",
      "0.27987958658260487\n",
      "0.2796652478708956\n",
      "0.2794512604733291\n",
      "0.27923762342259806\n",
      "0.27902433575528374\n",
      "0.27881139651183606\n",
      "0.2785988047365522\n",
      "0.27838655947755647\n",
      "0.27817465978677935\n",
      "0.27796310471993746\n",
      "0.27775189333651334\n",
      "0.27754102469973535\n",
      "0.27733049787655767\n",
      "0.2771203119376406\n",
      "0.2769104659573308\n",
      "0.27670095901364206\n",
      "0.2764917901882355\n",
      "0.27628295856640067\n",
      "0.27607446323703605\n",
      "0.27586630329263045\n",
      "0.2756584778292439\n",
      "0.2754509859464891\n",
      "0.27524382674751224\n",
      "0.2750369993389754\n",
      "0.2748305028310375\n",
      "0.27462433633733624\n",
      "0.27441849897496995\n",
      "0.2742129898644796\n",
      "0.27400780812983117\n",
      "0.27380295289839734\n",
      "0.2735984233009403\n",
      "0.273394218471594\n",
      "0.2731903375478467\n",
      "0.2729867796705239\n",
      "0.27278354398377075\n",
      "0.2725806296350355\n",
      "0.27237803577505204\n",
      "0.27217576155782314\n",
      "0.27197380614060407\n",
      "0.2717721686838855\n",
      "0.2715708483513771\n",
      "0.27136984430999145\n",
      "0.27116915572982697\n",
      "0.27096878178415273\n",
      "0.27076872164939125\n",
      "0.2705689745051035\n",
      "0.2703695395339722\n",
      "0.2701704159217866\n",
      "0.2699716028574262\n",
      "0.26977309953284584\n",
      "0.2695749051430597\n",
      "0.269377018886126\n",
      "0.26917943996313176\n",
      "0.2689821675781775\n",
      "0.26878520093836256\n",
      "0.2685885392537693\n",
      "0.26839218173744894\n",
      "0.26819612760540623\n",
      "0.268000376076585\n",
      "0.2678049263728535\n",
      "0.2676097777189896\n",
      "0.26741492934266664\n",
      "0.26722038047443913\n",
      "0.267026130347728\n",
      "0.2668321781988068\n",
      "0.2666385232667878\n",
      "0.2664451647936073\n",
      "0.2662521020240125\n",
      "0.266059334205547\n",
      "0.26586686058853753\n",
      "0.2656746804260801\n",
      "0.2654827929740262\n",
      "0.26529119749096985\n",
      "0.26509989323823385\n",
      "0.2649088794798561\n",
      "0.26471815548257716\n",
      "0.26452772051582635\n",
      "0.2643375738517094\n",
      "0.26414771476499443\n",
      "0.2639581425331001\n",
      "0.2637688564360823\n",
      "0.26357985575662096\n",
      "0.26339113978000817\n",
      "0.26320270779413507\n",
      "0.26301455908947924\n",
      "0.2628266929590927\n",
      "0.2626391086985891\n",
      "0.2624518056061316\n",
      "0.26226478298242073\n",
      "0.26207804013068164\n",
      "0.26189157635665317\n",
      "0.26170539096857476\n",
      "0.2615194832771747\n",
      "0.2613338525956589\n",
      "0.2611484982396986\n",
      "0.26096341952741814\n",
      "0.2607786157793845\n",
      "0.26059408631859476\n",
      "0.2604098304704651\n",
      "0.26022584756281886\n",
      "0.2600421369258757\n",
      "0.2598586978922398\n",
      "0.25967552979688896\n",
      "0.2594926319771634\n",
      "0.2593100037727544\n",
      "0.25912764452569337\n",
      "0.258945553580341\n",
      "0.2587637302833763\n",
      "0.25858217398378547\n",
      "0.25840088403285144\n",
      "0.25821985978414325\n",
      "0.25803910059350454\n",
      "0.25785860581904424\n",
      "0.257678374821125\n",
      "0.25749840696235327\n",
      "0.2573187016075684\n",
      "0.25713925812383304\n",
      "0.25696007588042175\n",
      "0.2567811542488118\n",
      "0.2566024926026727\n",
      "0.2564240903178556\n",
      "0.2562459467723837\n",
      "0.25606806134644255\n",
      "0.2558904334223689\n",
      "0.25571306238464225\n",
      "0.25553594761987425\n",
      "0.25535908851679895\n",
      "0.2551824844662633\n",
      "0.25500613486121737\n",
      "0.25483003909670454\n",
      "0.2546541965698527\n",
      "0.25447860667986366\n",
      "0.2543032688280046\n",
      "0.2541281824175981\n",
      "0.2539533468540134\n",
      "0.2537787615446565\n",
      "0.25360442589896137\n",
      "0.25343033932838044\n",
      "0.2532565012463759\n",
      "0.25308291106841024\n",
      "0.2529095682119373\n",
      "0.2527364720963935\n",
      "0.2525636221431886\n",
      "0.25239101777569745\n",
      "0.2522186584192502\n",
      "0.2520465435011244\n",
      "0.2518746724505358\n",
      "0.25170304469862986\n",
      "0.25153165967847335\n",
      "0.251360516825045\n",
      "0.251189615575228\n",
      "0.25101895536780094\n",
      "0.25084853564342896\n",
      "0.25067835584465636\n",
      "0.25050841541589774\n",
      "0.2503387138034294\n",
      "0.25016925045538174\n",
      "0.2500000248217306\n",
      "0.24983103635428927\n",
      "0.24966228450670025\n",
      "0.24949376873442752\n",
      "0.24932548849474803\n",
      "0.24915744324674421\n",
      "0.24898963245129555\n",
      "0.24882205557107115\n",
      "0.24865471207052178\n",
      "0.24848760141587162\n",
      "0.24832072307511135\n",
      "0.24815407651798968\n",
      "0.24798766121600582\n",
      "0.2478214766424023\n",
      "0.2476555222721567\n",
      "0.24748979758197473\n",
      "0.24732430205028233\n",
      "0.24715903515721832\n",
      "0.24699399638462685\n",
      "0.2468291852160503\n",
      "0.24666460113672176\n",
      "0.2465002436335574\n",
      "0.24633611219514995\n",
      "0.24617220631176082\n",
      "0.24600852547531307\n",
      "0.2458450691793844\n",
      "0.24568183691919984\n",
      "0.24551882819162507\n",
      "0.24535604249515877\n",
      "0.24519347932992613\n",
      "0.24503113819767164\n",
      "0.2448690186017522\n",
      "0.24470712004713036\n",
      "0.24454544204036727\n",
      "0.24438398408961612\n",
      "0.24422274570461497\n",
      "0.24406172639668036\n",
      "0.24390092567870053\n",
      "0.2437403430651287\n",
      "0.2435799780719764\n",
      "0.2434198302168068\n",
      "0.24325989901872846\n",
      "0.2431001839983885\n",
      "0.2429406846779662\n",
      "0.24278140058116646\n",
      "0.2426223312332135\n",
      "0.2424634761608445\n",
      "0.24230483489230306\n",
      "0.2421464069573328\n",
      "0.24198819188717147\n",
      "0.24183018921454444\n",
      "0.2416723984736583\n",
      "0.24151481920019494\n",
      "0.24135745093130523\n",
      "0.2412002932056031\n",
      "0.241043345563159\n",
      "0.24088660754549443\n",
      "0.24073007869557536\n",
      "0.24057375855780647\n",
      "0.24041764667802532\n",
      "0.2402617426034961\n",
      "0.24010604588290377\n",
      "0.23995055606634863\n",
      "0.23979527270533957\n",
      "0.23964019535278938\n",
      "0.23948532356300792\n",
      "0.23933065689169683\n",
      "0.23917619489594427\n",
      "0.23902193713421793\n",
      "0.2388678831663608\n",
      "0.23871403255358453\n",
      "0.23856038485846418\n",
      "0.23840693964493279\n",
      "0.23825369647827555\n",
      "0.2381006549251242\n",
      "0.23794781455345201\n",
      "0.23779517493256758\n",
      "0.23764273563311014\n",
      "0.23749049622704355\n",
      "0.23733845628765146\n",
      "0.2371866153895312\n",
      "0.23703497310858926\n",
      "0.2368835290220355\n",
      "0.23673228270837782\n",
      "0.23658123374741719\n",
      "0.23643038172024222\n",
      "0.2362797262092241\n",
      "0.2361292667980113\n",
      "0.23597900307152442\n",
      "0.23582893461595122\n",
      "0.23567906101874123\n",
      "0.23552938186860106\n",
      "0.235379896755489\n",
      "0.23523060527061027\n",
      "0.2350815070064118\n",
      "0.2349326015565773\n",
      "0.2347838885160224\n",
      "0.23463536748089\n",
      "0.23448703804854462\n",
      "0.2343388998175681\n",
      "0.23419095238775478\n",
      "0.23404319536010643\n",
      "0.23389562833682742\n",
      "0.23374825092132026\n",
      "0.23360106271818046\n",
      "0.2334540633331921\n",
      "0.23330725237332273\n",
      "0.23316062944671945\n",
      "0.2330141941627033\n",
      "0.23286794613176537\n",
      "0.2327218849655616\n",
      "0.23257601027690866\n",
      "0.23243032167977934\n",
      "0.23228481878929755\n",
      "0.2321395012217341\n",
      "0.23199436859450265\n",
      "0.23184942052615423\n",
      "0.23170465663637363\n",
      "0.23156007654597452\n",
      "0.23141567987689526\n",
      "0.2312714662521944\n",
      "0.23112743529604635\n",
      "0.23098358663373683\n",
      "0.23083991989165878\n",
      "0.23069643469730816\n",
      "0.23055313067927927\n",
      "0.23041000746726084\n",
      "0.23026706469203131\n",
      "0.23012430198545544\n",
      "0.2299817189804792\n",
      "0.2298393153111259\n",
      "0.2296970906124925\n",
      "0.2295550445207446\n",
      "0.22941317667311326\n",
      "0.22927148670788983\n",
      "0.2291299742644229\n",
      "0.2289886389831135\n",
      "0.22884748050541145\n",
      "0.2287064984738112\n",
      "0.22856569253184766\n",
      "0.2284250623240926\n",
      "0.2282846074961503\n",
      "0.22814432769465368\n",
      "0.22800422256726066\n",
      "0.22786429176264977\n",
      "0.22772453493051678\n",
      "0.2275849517215702\n",
      "0.2274455417875279\n",
      "0.22730630478111347\n",
      "0.22716724035605132\n",
      "0.2270283481670644\n",
      "0.2268896278698691\n",
      "0.22675107912117232\n",
      "0.22661270157866706\n",
      "0.2264744949010294\n",
      "0.22633645874791417\n",
      "0.2261985927799516\n",
      "0.2260608966587435\n",
      "0.22592337004685967\n",
      "0.22578601260783404\n",
      "0.2256488240061617\n",
      "0.2255118039072941\n",
      "0.2253749519776367\n",
      "0.22523826788454462\n",
      "0.22510175129631937\n",
      "0.22496540188220523\n",
      "0.22482921931238573\n",
      "0.22469320325797998\n",
      "0.22455735339103958\n",
      "0.22442166938454478\n",
      "0.2242861509124011\n",
      "0.22415079764943596\n",
      "0.22401560927139513\n",
      "0.22388058545493936\n",
      "0.22374572587764124\n",
      "0.22361103021798115\n",
      "0.2234764981553446\n",
      "0.2233421293700187\n",
      "0.22320792354318833\n",
      "0.22307388035693357\n",
      "0.22293999949422566\n",
      "0.2228062806389245\n",
      "0.22267272347577463\n",
      "0.22253932769040227\n",
      "0.22240609296931235\n",
      "0.22227301899988472\n",
      "0.22214010547037127\n",
      "0.22200735206989286\n",
      "0.22187475848843569\n",
      "0.22174232441684863\n",
      "0.22161004954683974\n",
      "0.2214779335709731\n",
      "0.22134597618266588\n",
      "0.22121417707618507\n",
      "0.22108253594664437\n",
      "0.2209510524900015\n",
      "0.22081972640305422\n",
      "0.22068855738343837\n",
      "0.22055754512962394\n",
      "0.2204266893409127\n",
      "0.22029598971743447\n",
      "0.22016544596014484\n",
      "0.22003505777082175\n",
      "0.21990482485206259\n",
      "0.21977474690728124\n",
      "0.21964482364070526\n",
      "0.21951505475737268\n",
      "0.2193854399631292\n",
      "0.2192559789646254\n",
      "0.21912667146931386\n",
      "0.21899751718544577\n",
      "0.21886851582206895\n",
      "0.21873966708902398\n",
      "0.21861097069694213\n",
      "0.21848242635724227\n",
      "0.21835403378212778\n",
      "0.2182257926845844\n",
      "0.21809770277837656\n",
      "0.21796976377804517\n",
      "0.2178419753989051\n",
      "0.21771433735704154\n",
      "0.21758684936930814\n",
      "0.2174595111533236\n",
      "0.21733232242746936\n",
      "0.21720528291088684\n",
      "0.21707839232347456\n",
      "0.21695165038588574\n",
      "0.21682505681952502\n",
      "0.2166986113465467\n",
      "0.21657231368985147\n",
      "0.21644616357308363\n",
      "0.21632016072062904\n",
      "0.21619430485761226\n",
      "0.21606859570989354\n",
      "0.21594303300406675\n",
      "0.21581761646745665\n",
      "0.21569234582811625\n",
      "0.21556722081482416\n",
      "0.21544224115708246\n",
      "0.21531740658511353\n",
      "0.21519271682985788\n",
      "0.21506817162297195\n",
      "0.21494377069682477\n",
      "0.21481951378449643\n",
      "0.2146954006197746\n",
      "0.21457143093715314\n",
      "0.2144476044718285\n",
      "0.21432392095969838\n",
      "0.21420038013735837\n",
      "0.21407698174210008\n",
      "0.21395372551190842\n",
      "0.21383061118545937\n",
      "0.21370763850211752\n",
      "0.21358480720193376\n",
      "0.2134621170256427\n",
      "0.2133395677146603\n",
      "0.2132171590110819\n",
      "0.21309489065767956\n",
      "0.21297276239789964\n",
      "0.2128507739758605\n",
      "0.2127289251363507\n",
      "0.2126072156248257\n",
      "0.21248564518740656\n",
      "0.21236421357087715\n",
      "0.2122429205226818\n",
      "0.21212176579092323\n",
      "0.21200074912436043\n",
      "0.2118798702724058\n",
      "0.2117591289851236\n",
      "0.2116385250132276\n",
      "0.21151805810807833\n",
      "0.21139772802168147\n",
      "0.2112775345066853\n",
      "0.21115747731637885\n",
      "0.21103755620468914\n",
      "0.2109177709261796\n",
      "0.21079812123604755\n",
      "0.21067860689012227\n",
      "0.21055922764486257\n",
      "0.21043998325735497\n",
      "0.2103208734853114\n",
      "0.21020189808706688\n",
      "0.21008305682157785\n",
      "0.20996434944841988\n",
      "0.20984577572778526\n",
      "0.2097273354204814\n",
      "0.2096090282879287\n",
      "0.20949085409215792\n",
      "0.20937281259580884\n",
      "0.20925490356212767\n",
      "0.20913712675496562\n",
      "0.20901948193877617\n",
      "0.2089019688786132\n",
      "0.20878458734012956\n",
      "0.20866733708957436\n",
      "0.20855021789379138\n",
      "0.20843322952021684\n",
      "0.2083163717368775\n",
      "0.20819964431238877\n",
      "0.2080830470159527\n",
      "0.20796657961735607\n",
      "0.20785024188696793\n",
      "0.20773403359573883\n",
      "0.20761795451519757\n",
      "0.20750200441744998\n",
      "0.20738618307517712\n",
      "0.2072704902616327\n",
      "0.20715492575064196\n",
      "0.20703948931659938\n",
      "0.2069241807344667\n",
      "0.2068089997797712\n",
      "0.20669394622860385\n",
      "0.2065790198576174\n",
      "0.20646422044402438\n",
      "0.2063495477655956\n",
      "0.2062350016006581\n",
      "0.2061205817280931\n",
      "0.2060062879273345\n",
      "0.2058921199783671\n",
      "0.20577807766172432\n",
      "0.2056641607584871\n",
      "0.20555036905028132\n",
      "0.20543670231927685\n",
      "0.2053231603481849\n",
      "0.20520974292025707\n",
      "0.20509644981928282\n",
      "0.2049832808295882\n",
      "0.20487023573603427\n",
      "0.20475731432401456\n",
      "0.20464451637945416\n",
      "0.20453184168880761\n",
      "0.20441929003905712\n",
      "0.20430686121771113\n",
      "0.20419455501280204\n",
      "0.2040823712128855\n",
      "0.20397030960703746\n",
      "0.2038583699848535\n",
      "0.20374655213644668\n",
      "0.20363485585244612\n",
      "0.20352328092399474\n",
      "0.20341182714274836\n",
      "0.20330049430087355\n",
      "0.20318928219104632\n",
      "0.2030781906064498\n",
      "0.2029672193407739\n",
      "0.20285636818821204\n",
      "0.2027456369434608\n",
      "0.20263502540171768\n",
      "0.20252453335867993\n",
      "0.20241416061054227\n",
      "0.20230390695399603\n",
      "0.20219377218622717\n",
      "0.2020837561049146\n",
      "0.20197385850822885\n",
      "0.20186407919483054\n",
      "0.20175441796386834\n",
      "0.20164487461497793\n",
      "0.20153544894828054\n",
      "0.2014261407643806\n",
      "0.20131694986436494\n",
      "0.2012078760498012\n",
      "0.20109891912273592\n",
      "0.20099007888569326\n",
      "0.20088135514167343\n",
      "0.2007727476941514\n",
      "0.20066425634707488\n",
      "0.20055588090486343\n",
      "0.20044762117240641\n",
      "0.20033947695506188\n",
      "0.20023144805865495\n",
      "0.20012353428947646\n",
      "0.2000157354542811\n",
      "0.19990805136028666\n",
      "0.19980048181517165\n",
      "0.19969302662707467\n",
      "0.19958568560459253\n",
      "0.19947845855677904\n",
      "0.19937134529314318\n",
      "0.19926434562364803\n",
      "0.19915745935870952\n",
      "0.1990506863091942\n",
      "0.19894402628641883\n",
      "0.1988374791021484\n",
      "0.19873104456859456\n",
      "0.19862472249841487\n",
      "0.19851851270471058\n",
      "0.1984124150010263\n",
      "0.19830642920134728\n",
      "0.1982005551200994\n",
      "0.1980947925721468\n",
      "0.19798914137279083\n",
      "0.19788360133776917\n",
      "0.1977781722832534\n",
      "0.19767285402584875\n",
      "0.19756764638259214\n",
      "0.1974625491709509\n",
      "0.1973575622088217\n",
      "0.19725268531452897\n",
      "0.1971479183068236\n",
      "0.19704326100488184\n",
      "0.19693871322830347\n",
      "0.19683427479711124\n",
      "0.19672994553174886\n",
      "0.1966257252530802\n",
      "0.1965216137823876\n",
      "0.1964176109413709\n",
      "0.19631371655214616\n",
      "0.1962099304372441\n",
      "0.19610625241960883\n",
      "0.19600268232259702\n",
      "0.1958992199699762\n",
      "0.1957958651859237\n",
      "0.19569261779502528\n",
      "0.19558947762227386\n",
      "0.1954864444930685\n",
      "0.19538351823321298\n",
      "0.1952806986689145\n",
      "0.19517798562678274\n",
      "0.19507537893382826\n",
      "0.19497287841746141\n",
      "0.19487048390549114\n",
      "0.1947681952261241\n",
      "0.19466601220796276\n",
      "0.1945639346800049\n",
      "0.19446196247164166\n",
      "0.19436009541265725\n",
      "0.19425833333322698\n",
      "0.19415667606391648\n",
      "0.19405512343568032\n",
      "0.19395367527986093\n",
      "0.19385233142818764\n",
      "0.19375109171277496\n",
      "0.19364995596612214\n",
      "0.1935489240211111\n",
      "0.19344799571100613\n",
      "0.1933471708694525\n",
      "0.19324644933047494\n",
      "0.193145830928477\n",
      "0.19304531549823942\n",
      "0.1929449028749196\n",
      "0.19284459289404968\n",
      "0.19274438539153632\n",
      "0.19264428020365887\n",
      "0.19254427716706865\n",
      "0.19244437611878737\n",
      "0.19234457689620665\n",
      "0.19224487933708664\n",
      "0.19214528327955463\n",
      "0.19204578856210447\n",
      "0.19194639502359487\n",
      "0.19184710250324905\n",
      "0.19174791084065299\n",
      "0.19164881987575477\n",
      "0.1915498294488632\n",
      "0.19145093940064703\n",
      "0.1913521495721337\n",
      "0.19125345980470823\n",
      "0.19115486994011238\n",
      "0.19105637982044324\n",
      "0.19095798928815289\n",
      "0.1908596981860462\n",
      "0.19076150635728084\n",
      "0.19066341364536576\n",
      "0.1905654198941602\n",
      "0.19046752494787275\n",
      "0.1903697286510602\n",
      "0.19027203084862646\n",
      "0.1901744313858221\n",
      "0.19007693010824211\n",
      "0.18997952686182645\n",
      "0.18988222149285763\n",
      "0.18978501384796068\n",
      "0.18968790377410172\n",
      "0.18959089111858682\n",
      "0.18949397572906146\n",
      "0.18939715745350902\n",
      "0.18930043614025022\n",
      "0.18920381163794192\n",
      "0.1891072837955763\n",
      "0.18901085246247953\n",
      "0.18891451748831117\n",
      "0.18881827872306295\n",
      "0.18872213601705792\n",
      "0.1886260892209497\n",
      "0.18853013818572092\n",
      "0.18843428276268293\n",
      "0.1883385228034744\n",
      "0.18824285816006045\n",
      "0.18814728868473196\n",
      "0.18805181423010423\n",
      "0.18795643464911632\n",
      "0.1878611497950302\n",
      "0.18776595952142935\n",
      "0.18767086368221822\n",
      "0.18757586213162133\n",
      "0.18748095472418222\n",
      "0.18738614131476242\n",
      "0.1872914217585406\n",
      "0.18719679591101188\n",
      "0.18710226362798665\n",
      "0.1870078247655896\n",
      "0.18691347918025938\n",
      "0.18681922672874698\n",
      "0.18672506726811502\n",
      "0.18663100065573734\n",
      "0.1865370267492975\n",
      "0.18644314540678805\n",
      "0.18634935648651002\n",
      "0.18625565984707157\n",
      "0.18616205534738736\n",
      "0.18606854284667732\n",
      "0.18597512220446652\n",
      "0.1858817932805835\n",
      "0.1857885559351599\n",
      "0.18569541002862938\n",
      "0.1856023554217268\n",
      "0.18550939197548738\n",
      "0.18541651955124597\n",
      "0.18532373801063587\n",
      "0.1852310472155882\n",
      "0.1851384470283314\n",
      "0.18504593731138952\n",
      "0.18495351792758224\n",
      "0.18486118874002352\n",
      "0.184768949612121\n",
      "0.18467680040757498\n",
      "0.1845847409903779\n",
      "0.18449277122481314\n",
      "0.18440089097545448\n",
      "0.18430910010716522\n",
      "0.18421739848509713\n",
      "0.18412578597469018\n",
      "0.18403426244167093\n",
      "0.1839428277520525\n",
      "0.18385148177213342\n",
      "0.18376022436849673\n",
      "0.18366905540800924\n",
      "0.18357797475782114\n",
      "0.1834869822853644\n",
      "0.18339607785835263\n",
      "0.1833052613447802\n",
      "0.18321453261292123\n",
      "0.18312389153132905\n",
      "0.18303333796883509\n",
      "0.1829428717945485\n",
      "0.18285249287785502\n",
      "0.18276220108841662\n",
      "0.18267199629617006\n",
      "0.1825818783713272\n",
      "0.18249184718437295\n",
      "0.18240190260606542\n",
      "0.18231204450743496\n",
      "0.18222227275978312\n",
      "0.18213258723468226\n",
      "0.18204298780397454\n",
      "0.1819534743397714\n",
      "0.18186404671445255\n",
      "0.18177470480066546\n",
      "0.18168544847132445\n",
      "0.18159627759961017\n",
      "0.18150719205896854\n",
      "0.18141819172311024\n",
      "0.18132927646600996\n",
      "0.18124044616190577\n",
      "0.18115170068529807\n",
      "0.1810630399109492\n",
      "0.18097446371388246\n",
      "0.18088597196938172\n",
      "0.18079756455299031\n",
      "0.18070924134051067\n",
      "0.1806210022080032\n",
      "0.18053284703178626\n",
      "0.18044477568843456\n",
      "0.18035678805477925\n",
      "0.18026888400790664\n",
      "0.18018106342515805\n",
      "0.18009332618412863\n",
      "0.18000567216266672\n",
      "0.17991810123887353\n",
      "0.17983061329110214\n",
      "0.1797432081979568\n",
      "0.17965588583829242\n",
      "0.17956864609121376\n",
      "0.17948148883607482\n",
      "0.17939441395247804\n",
      "0.17930742132027372\n",
      "0.1792205108195595\n",
      "0.17913368233067936\n",
      "0.17904693573422314\n",
      "0.17896027091102604\n",
      "0.17887368774216736\n",
      "0.17878718610897051\n",
      "0.17870076589300238\n",
      "0.1786144269760717\n",
      "0.1785281692402297\n",
      "0.17844199256776846\n",
      "0.17835589684122088\n",
      "0.1782698819433594\n",
      "0.17818394775719623\n",
      "0.17809809416598182\n",
      "0.17801232105320478\n",
      "0.17792662830259096\n",
      "0.17784101579810307\n",
      "0.17775548342393982\n",
      "0.17767003106453527\n",
      "0.17758465860455847\n",
      "0.1774993659289124\n",
      "0.1774141529227338\n",
      "0.1773290194713923\n",
      "0.17724396546048965\n",
      "0.17715899077585967\n",
      "0.17707409530356671\n",
      "0.17698927892990596\n",
      "0.17690454154140234\n",
      "0.17681988302481\n",
      "0.17673530326711154\n",
      "0.17665080215551768\n",
      "0.17656637957746668\n",
      "0.17648203542062335\n",
      "0.1763977695728786\n",
      "0.17631358192234908\n",
      "0.1762294723573767\n",
      "0.17614544076652722\n",
      "0.17606148703859048\n",
      "0.17597761106257942\n",
      "0.1758938127277296\n",
      "0.17581009192349878\n",
      "0.1757264485395659\n",
      "0.17564288246583068\n",
      "0.17555939359241343\n",
      "0.17547598180965396\n",
      "0.17539264700811108\n",
      "0.1753093890785622\n",
      "0.1752262079120027\n",
      "0.17514310339964534\n",
      "0.17506007543291957\n",
      "0.17497712390347117\n",
      "0.17489424870316173\n",
      "0.17481144972406737\n",
      "0.17472872685847946\n",
      "0.17464607999890286\n",
      "0.174563509038056\n",
      "0.17448101386887013\n",
      "0.17439859438448874\n",
      "0.17431625047826715\n",
      "0.17423398204377186\n",
      "0.1741517889747797\n",
      "0.174069671165278\n",
      "0.17398762850946337\n",
      "0.1739056609017416\n",
      "0.17382376823672657\n",
      "0.17374195040924045\n",
      "0.1736602073143125\n",
      "0.17357853884717891\n",
      "0.17349694490328207\n",
      "0.17341542537827007\n",
      "0.17333398016799645\n",
      "0.17325260916851923\n",
      "0.17317131227610044\n",
      "0.17309008938720608\n",
      "0.1730089403985049\n",
      "0.17292786520686845\n",
      "0.17284686370937005\n",
      "0.1727659358032849\n",
      "0.1726850813860888\n",
      "0.17260430035545846\n",
      "0.17252359260927005\n",
      "0.17244295804559961\n",
      "0.17236239656272181\n",
      "0.1722819080591099\n",
      "0.17220149243343505\n",
      "0.17212114958456567\n",
      "0.17204087941156712\n",
      "0.1719606818137014\n",
      "0.17188055669042587\n",
      "0.17180050394139376\n",
      "0.17172052346645295\n",
      "0.17164061516564552\n",
      "0.17156077893920788\n",
      "0.17148101468756952\n",
      "0.17140132231135266\n",
      "0.17132170171137243\n",
      "0.17124215278863514\n",
      "0.17116267544433936\n",
      "0.17108326957987388\n",
      "0.17100393509681816\n",
      "0.1709246718969418\n",
      "0.17084547988220358\n",
      "0.17076635895475145\n",
      "0.17068730901692178\n",
      "0.17060832997123906\n",
      "0.17052942172041513\n",
      "0.17045058416734915\n",
      "0.17037181721512668\n",
      "0.17029312076701963\n",
      "0.17021449472648523\n",
      "0.1701359389971662\n",
      "0.17005745348288986\n",
      "0.16997903808766776\n",
      "0.16990069271569508\n",
      "0.16982241727135078\n",
      "0.16974421165919615\n",
      "0.1696660757839752\n",
      "0.16958800955061365\n",
      "0.169510012864219\n",
      "0.16943208563007936\n",
      "0.16935422775366382\n",
      "0.16927643914062118\n",
      "0.1691987196967803\n",
      "0.16912106932814897\n",
      "0.16904348794091378\n",
      "0.16896597544143963\n",
      "0.16888853173626944\n",
      "0.16881115673212313\n",
      "0.16873385033589816\n",
      "0.16865661245466806\n",
      "0.16857944299568248\n",
      "0.16850234186636703\n",
      "0.16842530897432229\n",
      "0.16834834422732362\n",
      "0.16827144753332074\n",
      "0.16819461880043726\n",
      "0.1681178579369702\n",
      "0.16804116485138978\n",
      "0.16796453945233872\n",
      "0.16788798164863175\n",
      "0.1678114913492556\n",
      "0.1677350684633682\n",
      "0.16765871290029838\n",
      "0.16758242456954553\n",
      "0.1675062033807788\n",
      "0.16743004924383736\n",
      "0.16735396206872932\n",
      "0.16727794176563154\n",
      "0.16720198824488952\n",
      "0.16712610141701637\n",
      "0.16705028119269305\n",
      "0.16697452748276737\n",
      "0.16689884019825413\n",
      "0.16682321925033405\n",
      "0.16674766455035422\n",
      "0.16667217600982676\n",
      "0.16659675354042905\n",
      "0.16652139705400326\n",
      "0.16644610646255575\n",
      "0.16637088167825648\n",
      "0.16629572261343942\n",
      "0.16622062918060085\n",
      "0.16614560129240039\n",
      "0.1660706388616594\n",
      "0.16599574180136165\n",
      "0.16592091002465184\n",
      "0.165846143444836\n",
      "0.1657714419753808\n",
      "0.16569680552991317\n",
      "0.16562223402222\n",
      "0.16554772736624754\n",
      "0.16547328547610113\n",
      "0.1653989082660452\n",
      "0.16532459565050203\n",
      "0.16525034754405213\n",
      "0.16517616386143358\n",
      "0.16510204451754146\n",
      "0.16502798942742777\n",
      "0.16495399850630107\n",
      "0.16488007166952565\n",
      "0.1648062088326217\n",
      "0.16473240991126462\n",
      "0.16465867482128474\n",
      "0.1645850034786668\n",
      "0.16451139579954993\n",
      "0.16443785170022684\n",
      "0.1643643710971437\n",
      "0.16429095390689982\n",
      "0.1642176000462471\n",
      "0.16414430943208963\n",
      "0.16407108198148382\n",
      "0.16399791761163718\n",
      "0.1639248162399088\n",
      "0.16385177778380833\n",
      "0.16377880216099608\n",
      "0.1637058892892824\n",
      "0.16363303908662755\n",
      "0.1635602514711408\n",
      "0.16348752636108102\n",
      "0.16341486367485525\n",
      "0.16334226333101923\n",
      "0.16326972524827624\n",
      "0.16319724934547775\n",
      "0.16312483554162208\n",
      "0.16305248375585443\n",
      "0.16298019390746687\n",
      "0.16290796591589748\n",
      "0.16283579970073006\n",
      "0.16276369518169428\n",
      "0.16269165227866458\n",
      "0.16261967091166069\n",
      "0.16254775100084623\n",
      "0.16247589246652952\n",
      "0.16240409522916227\n",
      "0.16233235920933978\n",
      "0.16226068432780053\n",
      "0.16218907050542553\n",
      "0.16211751766323856\n",
      "0.16204602572240512\n",
      "0.1619745946042328\n",
      "0.16190322423017034\n",
      "0.1618319145218077\n",
      "0.16176066540087555\n",
      "0.16168947678924503\n",
      "0.16161834860892718\n",
      "0.161547280782073\n",
      "0.16147627323097288\n",
      "0.16140532587805623\n",
      "0.16133443864589112\n",
      "0.1612636114571844\n",
      "0.16119284423478067\n",
      "0.1611221369016625\n",
      "0.16105148938094993\n",
      "0.1609809015959001\n",
      "0.1609103734699069\n",
      "0.16083990492650083\n",
      "0.16076949588934858\n",
      "0.16069914628225251\n",
      "0.1606288560291507\n",
      "0.16055862505411636\n",
      "0.16048845328135777\n",
      "0.16041834063521745\n",
      "0.1603482870401726\n",
      "0.1602782924208341\n",
      "0.16020835670194655\n",
      "0.16013847980838794\n",
      "0.16006866166516928\n",
      "0.15999890219743418\n",
      "0.1599292013304588\n",
      "0.1598595589896513\n",
      "0.15978997510055157\n",
      "0.15972044958883128\n",
      "0.1596509823802928\n",
      "0.15958157340086981\n",
      "0.15951222257662634\n",
      "0.15944292983375682\n",
      "0.15937369509858546\n",
      "0.15930451829756614\n",
      "0.15923539935728234\n",
      "0.1591663382044464\n",
      "0.15909733476589932\n",
      "0.15902838896861096\n",
      "0.15895950073967896\n",
      "0.15889067000632906\n",
      "0.15882189669591434\n",
      "0.15875318073591543\n",
      "0.15868452205393985\n",
      "0.15861592057772167\n",
      "0.15854737623512163\n",
      "0.15847888895412637\n",
      "0.1584104586628484\n",
      "0.1583420852895259\n",
      "0.15827376876252208\n",
      "0.15820550901032523\n",
      "0.1581373059615484\n",
      "0.1580691595449289\n",
      "0.15800106968932792\n",
      "0.1579330363237311\n",
      "0.1578650593772469\n",
      "0.15779713877910753\n",
      "0.1577292744586679\n",
      "0.15766146634540573\n",
      "0.15759371436892114\n",
      "0.15752601845893624\n",
      "0.15745837854529512\n",
      "0.15739079455796354\n",
      "0.15732326642702826\n",
      "0.15725579408269738\n",
      "0.15718837745529948\n",
      "0.1571210164752837\n",
      "0.1570537110732194\n",
      "0.15698646117979584\n",
      "0.1569192667258219\n",
      "0.15685212764222597\n",
      "0.15678504386005537\n",
      "0.15671801531047624\n",
      "0.1566510419247735\n",
      "0.15658412363435018\n",
      "0.15651726037072736\n",
      "0.15645045206554384\n",
      "0.15638369865055612\n",
      "0.15631700005763774\n",
      "0.1562503562187792\n",
      "0.1561837670660879\n",
      "0.15611723253178741\n",
      "0.15605075254821768\n",
      "0.15598432704783438\n",
      "0.15591795596320907\n",
      "0.15585163922702852\n",
      "0.1557853767720947\n",
      "0.15571916853132442\n",
      "0.15565301443774907\n",
      "0.1555869144245146\n",
      "0.15552086842488086\n",
      "0.15545487637222158\n",
      "0.15538893820002403\n",
      "0.15532305384188896\n",
      "0.15525722323153013\n",
      "0.15519144630277404\n",
      "0.15512572298956\n",
      "0.15506005322593935\n",
      "0.15499443694607576\n",
      "0.1549288740842445\n",
      "0.15486336457483257\n",
      "0.15479790835233825\n",
      "0.15473250535137084\n",
      "0.15466715550665058\n",
      "0.1546018587530082\n",
      "0.1545366150253849\n",
      "0.1544714242588317\n",
      "0.15440628638850978\n",
      "0.15434120134968962\n",
      "0.15427616907775132\n",
      "0.15421118950818397\n",
      "0.15414626257658554\n",
      "0.15408138821866263\n",
      "0.15401656637023034\n",
      "0.15395179696721162\n",
      "0.15388707994563777\n",
      "0.15382241524164733\n",
      "0.15375780279148665\n",
      "0.15369324253150893\n",
      "0.1536287343981746\n",
      "0.15356427832805078\n",
      "0.1534998742578108\n",
      "0.15343552212423475\n",
      "0.15337122186420832\n",
      "0.15330697341472302\n",
      "0.15324277671287614\n",
      "0.1531786316958701\n",
      "0.15311453830101254\n",
      "0.15305049646571575\n",
      "0.15298650612749698\n",
      "0.15292256722397773\n",
      "0.1528586796928834\n",
      "0.15279484347204383\n",
      "0.15273105849939206\n",
      "0.1526673247129651\n",
      "0.15260364205090277\n",
      "0.15254001045144833\n",
      "0.15247642985294763\n",
      "0.15241290019384898\n",
      "0.15234942141270352\n",
      "0.15228599344816396\n",
      "0.15222261623898534\n",
      "0.1521592897240241\n",
      "0.15209601384223842\n",
      "0.15203278853268754\n",
      "0.1519696137345318\n",
      "0.15190648938703236\n",
      "0.15184341542955093\n",
      "0.1517803918015497\n",
      "0.15171741844259073\n",
      "0.15165449529233646\n",
      "0.15159162229054857\n",
      "0.15152879937708874\n",
      "0.15146602649191745\n",
      "0.1514033035750946\n",
      "0.1513406305667788\n",
      "0.1512780074072274\n",
      "0.15121543403679608\n",
      "0.15115291039593862\n",
      "0.1510904364252073\n",
      "0.15102801206525157\n",
      "0.15096563725681886\n",
      "0.15090331194075385\n",
      "0.15084103605799842\n",
      "0.1507788095495915\n",
      "0.15071663235666846\n",
      "0.15065450442046152\n",
      "0.15059242568229902\n",
      "0.15053039608360566\n",
      "0.15046841556590185\n",
      "0.15040648407080365\n",
      "0.15034460154002294\n",
      "0.15028276791536663\n",
      "0.15022098313873683\n",
      "0.15015924715213044\n",
      "0.15009755989763923\n",
      "0.15003592131744936\n",
      "0.14997433135384117\n",
      "0.14991278994918933\n",
      "0.14985129704596206\n",
      "0.14978985258672173\n",
      "0.14972845651412361\n",
      "0.14966710877091677\n",
      "0.14960580929994313\n",
      "0.14954455804413738\n",
      "0.1494833549465271\n",
      "0.14942219995023243\n",
      "0.14936109299846545\n",
      "0.1493000340345307\n",
      "0.14923902300182446\n",
      "0.14917805984383475\n",
      "0.149117144504141\n",
      "0.14905627692641413\n",
      "0.1489954570544161\n",
      "0.14893468483199973\n",
      "0.14887396020310875\n",
      "0.14881328311177724\n",
      "0.14875265350212982\n",
      "0.14869207131838122\n",
      "0.14863153650483596\n",
      "0.14857104900588858\n",
      "0.14851060876602318\n",
      "0.14845021572981307\n",
      "0.14838986984192112\n",
      "0.1483295710470989\n",
      "0.14826931929018686\n",
      "0.14820911451611443\n",
      "0.14814895666989916\n",
      "0.148088845696647\n",
      "0.1480287815415519\n",
      "0.14796876414989593\n",
      "0.14790879346704863\n",
      "0.1478488694384675\n",
      "0.14778899200969678\n",
      "0.1477291611263684\n",
      "0.1476693767342011\n",
      "0.1476096387790004\n",
      "0.14754994720665843\n",
      "0.147490301963154\n",
      "0.14743070299455185\n",
      "0.14737115024700298\n",
      "0.14731164366674432\n",
      "0.1472521832000985\n",
      "0.14719276879347365\n",
      "0.1471334003933634\n",
      "0.14707407794634642\n",
      "0.14701480139908643\n",
      "0.14695557069833196\n",
      "0.1468963857909163\n",
      "0.14683724662375736\n",
      "0.14677815314385695\n",
      "0.14671910529830134\n",
      "0.1466601030342607\n",
      "0.14660114629898885\n",
      "0.1465422350398234\n",
      "0.1464833692041853\n",
      "0.14642454873957883\n",
      "0.14636577359359124\n",
      "0.14630704371389283\n",
      "0.14624835904823663\n",
      "0.14618971954445814\n",
      "0.14613112515047547\n",
      "0.14607257581428876\n",
      "0.14601407148398027\n",
      "0.14595561210771432\n",
      "0.1458971976337367\n",
      "0.14583882801037504\n",
      "0.1457805031860381\n",
      "0.14572222310921598\n",
      "0.14566398772847997\n",
      "0.14560579699248202\n",
      "0.14554765084995494\n",
      "0.14548954924971214\n",
      "0.14543149214064718\n",
      "0.1453734794717342\n",
      "0.14531551119202715\n",
      "0.14525758725066004\n",
      "0.14519970759684647\n",
      "0.14514187217987964\n",
      "0.1450840809491324\n",
      "0.1450263338540564\n",
      "0.14496863084418288\n",
      "0.14491097186912152\n",
      "0.14485335687856118\n",
      "0.14479578582226896\n",
      "0.1447382586500908\n",
      "0.14468077531195056\n",
      "0.14462333575785044\n",
      "0.14456593993787048\n",
      "0.14450858780216863\n",
      "0.1444512793009804\n",
      "0.14439401438461885\n",
      "0.14433679300347435\n",
      "0.1442796151080144\n",
      "0.1442224806487836\n",
      "0.14416538957640337\n",
      "0.14410834184157173\n",
      "0.14405133739506346\n",
      "0.14399437618772964\n",
      "0.14393745817049755\n",
      "0.14388058329437053\n",
      "0.14382375151042798\n",
      "0.14376696276982498\n",
      "0.14371021702379222\n",
      "0.14365351422363587\n",
      "0.1435968543207376\n",
      "0.143540237266554\n",
      "0.14348366301261667\n",
      "0.14342713151053224\n",
      "0.1433706427119822\n",
      "0.14331419656872205\n",
      "0.14325779303258215\n",
      "0.14320143205546726\n",
      "0.14314511358935572\n",
      "0.14308883758630023\n",
      "0.14303260399842727\n",
      "0.14297641277793674\n",
      "0.14292026387710247\n",
      "0.14286415724827128\n",
      "0.14280809284386342\n",
      "0.1427520706163721\n",
      "0.1426960905183637\n",
      "0.14264015250247702\n",
      "0.1425842565214239\n",
      "0.1425284025279883\n",
      "0.1424725904750267\n",
      "0.14241682031546796\n",
      "0.14236109200231273\n",
      "0.14230540548863366\n",
      "0.14224976072757517\n",
      "0.1421941576723536\n",
      "0.1421385962762562\n",
      "0.142083076492642\n",
      "0.14202759827494116\n",
      "0.14197216157665477\n",
      "0.1419167663513551\n",
      "0.14186141255268486\n",
      "0.14180610013435768\n",
      "0.14175082905015748\n",
      "0.1416955992539388\n",
      "0.14164041069962613\n",
      "0.14158526334121424\n",
      "0.14153015713276765\n",
      "0.14147509202842093\n",
      "0.14142006798237805\n",
      "0.1413650849489127\n",
      "0.14131014288236796\n",
      "0.1412552417371559\n",
      "0.1412003814677581\n",
      "0.14114556202872486\n",
      "0.14109078337467543\n",
      "0.14103604546029772\n",
      "0.14098134824034814\n",
      "0.14092669166965172\n",
      "0.1408720757031016\n",
      "0.14081750029565926\n",
      "0.14076296540235406\n",
      "0.1407084709782834\n",
      "0.14065401697861235\n",
      "0.14059960335857366\n",
      "0.1405452300734676\n",
      "0.14049089707866166\n",
      "0.1404366043295908\n",
      "0.14038235178175684\n",
      "0.1403281393907288\n",
      "0.1402739671121425\n",
      "0.1402198349017002\n",
      "0.14016574271517113\n",
      "0.14011169050839073\n",
      "0.14005767823726079\n",
      "0.1400037058577495\n",
      "0.1399497733258906\n",
      "0.13989588059778432\n",
      "0.13984202762959647\n",
      "0.13978821437755842\n",
      "0.1397344407979674\n",
      "0.13968070684718573\n",
      "0.13962701248164108\n",
      "0.13957335765782652\n",
      "0.13951974233229997\n",
      "0.1394661664616842\n",
      "0.13941263000266688\n",
      "0.1393591329120004\n",
      "0.13930567514650152\n",
      "0.13925225666305158\n",
      "0.13919887741859596\n",
      "0.13914553737014454\n",
      "0.1390922364747709\n",
      "0.13903897468961285\n",
      "0.1389857519718717\n",
      "0.1389325682788126\n",
      "0.13887942356776417\n",
      "0.13882631779611845\n",
      "0.13877325092133086\n",
      "0.13872022290091984\n",
      "0.13866723369246703\n",
      "0.13861428325361694\n",
      "0.13856137154207687\n",
      "0.1385084985156169\n",
      "0.13845566413206953\n",
      "0.1384028683493298\n",
      "0.1383501111253551\n",
      "0.13829739241816497\n",
      "0.138244712185841\n",
      "0.13819207038652692\n",
      "0.1381394669784281\n",
      "0.13808690191981168\n",
      "0.13803437516900674\n",
      "0.13798188668440334\n",
      "0.13792943642445316\n",
      "0.1378770243476692\n",
      "0.13782465041262562\n",
      "0.13777231457795736\n",
      "0.13772001680236054\n",
      "0.13766775704459194\n",
      "0.13761553526346904\n",
      "0.13756335141786988\n",
      "0.13751120546673287\n",
      "0.13745909736905695\n",
      "0.13740702708390107\n",
      "0.13735499457038428\n",
      "0.13730299978768584\n",
      "0.13725104269504457\n",
      "0.13719912325175931\n",
      "0.1371472414171884\n",
      "0.13709539715074975\n",
      "0.13704359041192057\n",
      "0.13699182116023761\n",
      "0.13694008935529672\n",
      "0.13688839495675267\n",
      "0.13683673792431933\n",
      "0.1367851182177695\n",
      "0.13673353579693448\n",
      "0.13668199062170452\n",
      "0.13663048265202804\n",
      "0.13657901184791216\n",
      "0.13652757816942224\n",
      "0.1364761815766817\n",
      "0.13642482202987202\n",
      "0.13637349948923297\n",
      "0.1363222139150619\n",
      "0.13627096526771376\n",
      "0.1362197535076016\n",
      "0.13616857859519557\n",
      "0.1361174404910235\n",
      "0.13606633915567057\n",
      "0.1360152745497789\n",
      "0.13596424663404794\n",
      "0.13591325536923402\n",
      "0.13586230071615038\n",
      "0.13581138263566725\n",
      "0.13576050108871107\n",
      "0.13570965603626528\n",
      "0.1356588474393696\n",
      "train accuracy: 99.04306220095694 %\n",
      "test accuracy: 70.0 %\n"
     ]
    }
   ],
   "source": [
    "logistic_regression_model = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=2000, learning_rate=0.005, print_cost=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment**: Training accuracy is close to 100%. This is a good sanity check: your model is working and has high enough capacity to fit the training data. Test accuracy is 70%. It is actually not bad for this simple model, given the small dataset we used and that logistic regression is a linear classifier. But no worries, you'll build an even better classifier next week!\n",
    "\n",
    "Also, you see that the model is clearly overfitting the training data. Later in this specialization you will learn how to reduce overfitting, for example by using regularization. Using the code below (and changing the `index` variable) you can look at predictions on pictures of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1, you predicted that it is a \"cat\" picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture that was wrongly classified.\n",
    "index = 1\n",
    "plt.imshow(test_set_x[:, index].reshape((num_px, num_px, 3)))\n",
    "print (\"y = \" + str(test_set_y[0,index]) + \", you predicted that it is a \\\"\" + classes[int(logistic_regression_model['Y_prediction_test'][0,index])].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the cost function and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot learning curve (with costs)\n",
    "costs = np.squeeze(logistic_regression_model['costs'])\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Learning rate =\" + str(logistic_regression_model[\"learning_rate\"]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "You can see the cost decreasing. It shows that the parameters are being learned. However, you see that you could train the model even more on the training set. Try to increase the number of iterations in the cell above and rerun the cells. You might see that the training set accuracy goes up, but the test set accuracy goes down. This is called overfitting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6 - Further analysis (optional/ungraded exercise) ##\n",
    "\n",
    "Congratulations on building your first image classification model. Let's analyze it further, and examine possible choices for the learning rate $\\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choice of learning rate ####\n",
    "\n",
    "**Reminder**:\n",
    "In order for Gradient Descent to work you must choose the learning rate wisely. The learning rate $\\alpha$  determines how rapidly we update the parameters. If the learning rate is too large we may \"overshoot\" the optimal value. Similarly, if it is too small we will need too many iterations to converge to the best values. That's why it is crucial to use a well-tuned learning rate.\n",
    "\n",
    "Let's compare the learning curve of our model with several choices of learning rates. Run the cell below. This should take about 1 minute. Feel free also to try different values than the three we have initialized the `learning_rates` variable to contain, and see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a model with learning rate: 0.01\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training a model with learning rate: 0.001\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Training a model with learning rate: 0.0001\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "models = {}\n",
    "\n",
    "for lr in learning_rates:\n",
    "    print (\"Training a model with learning rate: \" + str(lr))\n",
    "    models[str(lr)] = model(train_set_x, train_set_y, test_set_x, test_set_y, num_iterations=1500, learning_rate=lr, print_cost=False)\n",
    "    print ('\\n' + \"-------------------------------------------------------\" + '\\n')\n",
    "\n",
    "for lr in learning_rates:\n",
    "    plt.plot(np.squeeze(models[str(lr)][\"costs\"]), label=str(models[str(lr)][\"learning_rate\"]))\n",
    "\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (hundreds)')\n",
    "\n",
    "legend = plt.legend(loc='upper center', shadow=True)\n",
    "frame = legend.get_frame()\n",
    "frame.set_facecolor('0.90')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**: \n",
    "- Different learning rates give different costs and thus different predictions results.\n",
    "- If the learning rate is too large (0.01), the cost may oscillate up and down. It may even diverge (though in this example, using 0.01 still eventually ends up at a good value for the cost). \n",
    "- A lower cost doesn't mean a better model. You have to check if there is possibly overfitting. It happens when the training accuracy is a lot higher than the test accuracy.\n",
    "- In deep learning, we usually recommend that you: \n",
    "    - Choose the learning rate that better minimizes the cost function.\n",
    "    - If your model overfits, use other techniques to reduce overfitting. (We'll talk about this in later videos.) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7 - Test with your own image (optional/ungraded exercise) ##\n",
    "\n",
    "Congratulations on finishing this assignment. You can use your own image and see the output of your model. To do that:\n",
    "    1. Click on \"File\" in the upper bar of this notebook, then click \"Open\" to go on your Coursera Hub.\n",
    "    2. Add your image to this Jupyter Notebook's directory, in the \"images\" folder\n",
    "    3. Change your image's name in the following code\n",
    "    4. Run the code and check if the algorithm is right (1 = cat, 0 = non-cat)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the name of your image file\n",
    "my_image = \"my_image.jpg\"   \n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(Image.open(fname).resize((num_px, num_px)))\n",
    "plt.imshow(image)\n",
    "image = image / 255.\n",
    "image = image.reshape((1, num_px * num_px * 3)).T\n",
    "my_predicted_image = predict(logistic_regression_model[\"w\"], logistic_regression_model[\"b\"], image)\n",
    "\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "    \n",
    "**What to remember from this assignment:**\n",
    "1. Preprocessing the dataset is important.\n",
    "2. You implemented each function separately: initialize(), propagate(), optimize(). Then you built a model().\n",
    "3. Tuning the learning rate (which is an example of a \"hyperparameter\") can make a big difference to the algorithm. You will see more examples of this later in this course!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you'd like, we invite you to try different things on this Notebook. Make sure you submit before trying anything. Once you submit, things you can play with include:\n",
    "    - Play with the learning rate and the number of iterations\n",
    "    - Try different initialization methods and compare the results\n",
    "    - Test other preprocessings (center the data, or divide each row by its standard deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography:\n",
    "- http://www.wildml.com/2015/09/implementing-a-neural-network-from-scratch/\n",
    "- https://stats.stackexchange.com/questions/211436/why-do-we-normalize-images-by-subtracting-the-datasets-image-mean-and-not-the-c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
